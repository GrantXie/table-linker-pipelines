{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIR = '/data/amandeep/nih-dataset/organization'\n",
    "table_path = f'{HOME_DIR}/org_for_tl_with_qnode.tsv'\n",
    "f_name = table_path.split(\"/\")[-1]\n",
    "wikify_column_name = \"name,city,state,country\"\n",
    "final_score_column = \"siamese_prediction\"\n",
    "\n",
    "canonical_file_path = f'{HOME_DIR}/temp/canonical.csv'\n",
    "candidate_file_path = f'{HOME_DIR}/temp/candidates.csv'\n",
    "aux_field = 'graph_embedding_complex,class_count,property_count,context'\n",
    "temp_dir= f'{HOME_DIR}/temp/temp'\n",
    "\n",
    "aligned_pagerank_candidate_file_path = f'{HOME_DIR}/temp/apr_test.csv'\n",
    "model_file_path = './models/weighted_lr.pkl'\n",
    "ranking_model_file_path = './models/epoch_5_loss_0.09882864356040955_top1_0.8968926553672316.pth'\n",
    "min_max_scaler_path = './models/normalization_factor.pkl'\n",
    "\n",
    "model_voted_candidate_file_path = f'{HOME_DIR}/temp/mv_test.csv'\n",
    "graph_embedding_file_path = f'{HOME_DIR}/temp/score_test.csv'\n",
    "\n",
    "lof_reciprocal_rank_file_path = f'{HOME_DIR}/temp/lof_rr_test.csv'\n",
    "lof_tfidf_file_path = f'{HOME_DIR}/temp/lof_tfidf_test.csv'\n",
    "lof_feature_file = f'{HOME_DIR}/temp/lof_feature.csv'\n",
    "context_score_file = f'{HOME_DIR}/temp/context_score_file.csv'\n",
    "\n",
    "output_model_pred_file = f'{HOME_DIR}/temp/model_prediction.csv'\n",
    "top5_links = f'{HOME_DIR}/temp/top5_links.csv'\n",
    "colorized_kg_links = f'{HOME_DIR}/temp/{f_name.strip(\".csv\")}_colorized.xlsx'\n",
    "\n",
    "graph_embedding_complex_file = f'{HOME_DIR}/temp/graph_embedding_complex.tsv'\n",
    "class_count_file = f'{HOME_DIR}/temp/class_count.tsv'\n",
    "property_count_file = f'{HOME_DIR}/temp/property_count.tsv'\n",
    "context_file = f'{HOME_DIR}/temp/context.tsv'\n",
    "index_url = 'http://ckg07:9200/wikidatadwd-augmented/'\n",
    "\n",
    "string_threshold = 0.9\n",
    "siamese_threshold = 0.9\n",
    "custom_context_file = '/Users/grantxie/test/coi3/coauthors.context.tsv.gz'\n",
    "gt = '/Users/grantxie/Downloads/groundtruth_new.csv'\n",
    "selection_save_path = 'test_selection.csv'\n",
    "labeled_path = 'test_eva.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['pagerank','retrieval_score','monge_elkan','monge_elkan_aliases','des_cont_jaccard',\n",
    "            'jaro_winkler','levenshtein','singleton','num_char','num_tokens',\n",
    "           'lof_class_count_tf_idf_score', 'lof_property_count_tf_idf_score',\n",
    "           'lof-graph-embedding-score', 'lof-reciprocal-rank', 'context_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/amandeep/nih-dataset/organization/org_for_tl_with_qnode.tsv\n"
     ]
    }
   ],
   "source": [
    "!ls \"$table_path\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canonicalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canonicalize Time: 0.13051271438598633s\n"
     ]
    }
   ],
   "source": [
    "!tl canonicalize -c \"$wikify_column_name\" --add-context \"$table_path\" -s org_node,city_node,state_node,country_node --tsv \\\n",
    "> \"$canonical_file_path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>row</th>\n",
       "      <th>label</th>\n",
       "      <th>context</th>\n",
       "      <th>filename</th>\n",
       "      <th>column-id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>UNIVERSITY OF WASHINGTON</td>\n",
       "      <td>SEATTLE|WA|UNITED STATES</td>\n",
       "      <td>org_for_tl_with_qnode.tsv</td>\n",
       "      <td>org_for_tl_with_qnode.tsv-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CHARLES R. DREW UNIVERSITY OF MEDICAL &amp; SCIENCE</td>\n",
       "      <td>LOS ANGELES|CA|UNITED STATES</td>\n",
       "      <td>org_for_tl_with_qnode.tsv</td>\n",
       "      <td>org_for_tl_with_qnode.tsv-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>UNIVERSITY OF CALIFORNIA, SAN DIEGO</td>\n",
       "      <td>LA JOLLA|CA|UNITED STATES</td>\n",
       "      <td>org_for_tl_with_qnode.tsv</td>\n",
       "      <td>org_for_tl_with_qnode.tsv-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>UNIVERSITY OF MIAMI SCHOOL OF MEDICINE</td>\n",
       "      <td>CORAL GABLES|FL|UNITED STATES</td>\n",
       "      <td>org_for_tl_with_qnode.tsv</td>\n",
       "      <td>org_for_tl_with_qnode.tsv-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>BAYLOR UNIVERSITY</td>\n",
       "      <td>WACO|TX|UNITED STATES</td>\n",
       "      <td>org_for_tl_with_qnode.tsv</td>\n",
       "      <td>org_for_tl_with_qnode.tsv-0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   column  row                                            label  \\\n",
       "0       0    0                         UNIVERSITY OF WASHINGTON   \n",
       "1       0    1  CHARLES R. DREW UNIVERSITY OF MEDICAL & SCIENCE   \n",
       "2       0    2              UNIVERSITY OF CALIFORNIA, SAN DIEGO   \n",
       "3       0    3           UNIVERSITY OF MIAMI SCHOOL OF MEDICINE   \n",
       "4       0    4                                BAYLOR UNIVERSITY   \n",
       "\n",
       "                         context                   filename  \\\n",
       "0       SEATTLE|WA|UNITED STATES  org_for_tl_with_qnode.tsv   \n",
       "1   LOS ANGELES|CA|UNITED STATES  org_for_tl_with_qnode.tsv   \n",
       "2      LA JOLLA|CA|UNITED STATES  org_for_tl_with_qnode.tsv   \n",
       "3  CORAL GABLES|FL|UNITED STATES  org_for_tl_with_qnode.tsv   \n",
       "4          WACO|TX|UNITED STATES  org_for_tl_with_qnode.tsv   \n",
       "\n",
       "                     column-id  \n",
       "0  org_for_tl_with_qnode.tsv-0  \n",
       "1  org_for_tl_with_qnode.tsv-0  \n",
       "2  org_for_tl_with_qnode.tsv-0  \n",
       "3  org_for_tl_with_qnode.tsv-0  \n",
       "4  org_for_tl_with_qnode.tsv-0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(canonical_file_path, nrows = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 amandeep isdstaff 2742224 Aug  2 17:48 /data/amandeep/nih-dataset/organization/temp/canonical.csv\n"
     ]
    }
   ],
   "source": [
    "!ls -l $canonical_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(f_path, output_path):\n",
    "    df = pd.read_csv(f_path)\n",
    "    for column, gdf in df.groupby(by=['column']):\n",
    "        print(column, len(gdf))\n",
    "        d_list = np.array_split(gdf, 10)\n",
    "        for i, d in enumerate(d_list):\n",
    "            d.to_csv(f'{output_path}/split_{column}_{i}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6025\n",
      "1 6025\n",
      "2 6025\n",
      "3 6025\n"
     ]
    }
   ],
   "source": [
    "split(canonical_file_path, '/data/amandeep/nih-dataset/organization/nih-split')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Candidate Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def candidate_generation(path, output_path, class_count_path, prop_count_path, context_path, graph_embedding):\n",
    "    file_list = glob.glob(path + '/*.csv')\n",
    "    for i, file in tqdm(enumerate(file_list)):\n",
    "        st = time.time()\n",
    "        filename = file.split('/')[-1]\n",
    "        print(f\"{filename}: {i+1} of {len(file_list)}\")\n",
    "        output_file = f\"{output_path}/{filename}\"\n",
    "        \n",
    "        !tl clean -c label -o label_clean $file / \\\n",
    "        --url http://ckg07:9200 --index wikidatadwd-augmented \\\n",
    "        get-fuzzy-augmented-matches -c label_clean \\\n",
    "        --auxiliary-fields {aux_field} \\\n",
    "        --auxiliary-folder \"$temp_dir\" / \\\n",
    "        --url http://ckg07:9200 --index wikidatadwd-augmented \\\n",
    "        get-exact-matches -c label_clean \\\n",
    "        --auxiliary-fields {aux_field} \\\n",
    "        --auxiliary-folder \"$temp_dir\" > \"$output_file\"\n",
    "        \n",
    "        for field in aux_field.split(','):\n",
    "            aux_list = []\n",
    "            for f in glob.glob(f'{temp_dir}/*{field}.tsv'):\n",
    "                aux_list.append(pd.read_csv(f, sep='\\t', dtype=object))\n",
    "            aux_df = pd.concat(aux_list).drop_duplicates(subset=['qnode'])\n",
    "            if field == 'class_count':\n",
    "                class_count_file = f\"{class_count_path}/{filename[:-4]}_class_count.tsv\"\n",
    "                aux_df.to_csv(class_count_file, sep='\\t', index=False)\n",
    "            elif field == 'property_count':\n",
    "                prop_count_file = f\"{prop_count_path}/{filename[:-4]}_prop_count.tsv\"\n",
    "                aux_df.to_csv(prop_count_file, sep='\\t', index=False)\n",
    "            elif field == 'context':\n",
    "                context_file = f\"{context_path}/{filename[:-4]}_context.tsv\"\n",
    "                aux_df.to_csv(context_file, sep='\\t', index=False)\n",
    "            else:\n",
    "                graph_embedding_file = f\"{graph_embedding}/{filename[:-4]}_graph_embedding_complex.tsv\"\n",
    "                aux_df.to_csv(graph_embedding_file, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '/data/amandeep/nih-dataset/organization/nih-split'\n",
    "output_path = '/data/amandeep/nih-dataset/organization/candidates'\n",
    "!mkdir -p $output_path\n",
    "\n",
    "class_count_path = '/data/amandeep/nih-dataset/organization/temp/class_c'\n",
    "!mkdir -p $class_count_path\n",
    "prop_count_path = '/data/amandeep/nih-dataset/organization/temp/prop_c'\n",
    "!mkdir -p $prop_count_path\n",
    "context_path = '/data/amandeep/nih-dataset/organization/temp/context'\n",
    "!mkdir -p $context_path\n",
    "graph_embedding = '/data/amandeep/nih-dataset/organization/temp/ge'\n",
    "!mkdir -p $graph_embedding\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_0.csv: 1 of 40\n",
      "clean Time: 0.03534221649169922s\n",
      "get-fuzzy-augmented-matches Time: 44.592395544052124s\n",
      "get-exact-matches Time: 3.4459550380706787s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:58, 58.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_1.csv: 2 of 40\n",
      "clean Time: 0.03396940231323242s\n",
      "get-fuzzy-augmented-matches Time: 43.86876440048218s\n",
      "get-exact-matches Time: 3.6438634395599365s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [01:56, 58.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_2.csv: 3 of 40\n",
      "clean Time: 0.0399777889251709s\n",
      "get-fuzzy-augmented-matches Time: 43.40606880187988s\n",
      "get-exact-matches Time: 3.4931576251983643s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [02:54, 57.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_3.csv: 4 of 40\n",
      "clean Time: 0.03672909736633301s\n",
      "get-fuzzy-augmented-matches Time: 40.4506721496582s\n",
      "get-exact-matches Time: 3.3564834594726562s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [03:48, 56.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_4.csv: 5 of 40\n",
      "clean Time: 0.02532649040222168s\n",
      "get-fuzzy-augmented-matches Time: 40.627663373947144s\n",
      "get-exact-matches Time: 3.366626024246216s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [04:43, 55.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_5.csv: 6 of 40\n",
      "clean Time: 0.03431987762451172s\n",
      "get-fuzzy-augmented-matches Time: 39.46259140968323s\n",
      "get-exact-matches Time: 3.4717140197753906s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [05:36, 54.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_6.csv: 7 of 40\n",
      "clean Time: 0.033527374267578125s\n",
      "get-fuzzy-augmented-matches Time: 37.73267960548401s\n",
      "get-exact-matches Time: 3.349005699157715s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [06:27, 53.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_7.csv: 8 of 40\n",
      "clean Time: 0.03268003463745117s\n",
      "get-fuzzy-augmented-matches Time: 38.122777462005615s\n",
      "get-exact-matches Time: 3.3154449462890625s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [07:18, 53.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_8.csv: 9 of 40\n",
      "clean Time: 0.040342092514038086s\n",
      "get-fuzzy-augmented-matches Time: 41.05448532104492s\n",
      "get-exact-matches Time: 3.2510900497436523s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [08:13, 53.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_9.csv: 10 of 40\n",
      "clean Time: 0.04243946075439453s\n",
      "get-fuzzy-augmented-matches Time: 38.77289056777954s\n",
      "get-exact-matches Time: 3.4492833614349365s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [09:06, 53.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_0.csv: 11 of 40\n",
      "clean Time: 0.03442263603210449s\n",
      "get-fuzzy-augmented-matches Time: 24.685161113739014s\n",
      "get-exact-matches Time: 3.703518867492676s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [09:48, 49.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_1.csv: 12 of 40\n",
      "clean Time: 0.025600671768188477s\n",
      "get-fuzzy-augmented-matches Time: 25.4673433303833s\n",
      "get-exact-matches Time: 4.2526116371154785s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [10:30, 47.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_2.csv: 13 of 40\n",
      "clean Time: 0.025448083877563477s\n",
      "get-fuzzy-augmented-matches Time: 25.372114181518555s\n",
      "get-exact-matches Time: 4.217370271682739s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [11:13, 45.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_3.csv: 14 of 40\n",
      "clean Time: 0.02054762840270996s\n",
      "get-fuzzy-augmented-matches Time: 24.584006309509277s\n",
      "get-exact-matches Time: 4.056403160095215s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [11:55, 44.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_4.csv: 15 of 40\n",
      "clean Time: 0.03737831115722656s\n",
      "get-fuzzy-augmented-matches Time: 26.66512441635132s\n",
      "get-exact-matches Time: 4.6266539096832275s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [12:39, 44.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_5.csv: 16 of 40\n",
      "clean Time: 0.025320053100585938s\n",
      "get-fuzzy-augmented-matches Time: 25.35082244873047s\n",
      "get-exact-matches Time: 4.280551195144653s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [13:23, 44.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_6.csv: 17 of 40\n",
      "clean Time: 0.02686619758605957s\n",
      "get-fuzzy-augmented-matches Time: 25.074878454208374s\n",
      "get-exact-matches Time: 4.174172401428223s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [14:06, 44.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_7.csv: 18 of 40\n",
      "clean Time: 0.028959035873413086s\n",
      "get-fuzzy-augmented-matches Time: 24.699471950531006s\n",
      "get-exact-matches Time: 3.7183055877685547s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [14:48, 43.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_8.csv: 19 of 40\n",
      "clean Time: 0.02055954933166504s\n",
      "get-fuzzy-augmented-matches Time: 23.98292827606201s\n",
      "get-exact-matches Time: 3.843311071395874s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [15:28, 42.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_9.csv: 20 of 40\n",
      "clean Time: 0.025316238403320312s\n",
      "get-fuzzy-augmented-matches Time: 26.953267097473145s\n",
      "get-exact-matches Time: 4.234764814376831s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [16:13, 43.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_0.csv: 21 of 40\n",
      "clean Time: 0.044812917709350586s\n",
      "get-fuzzy-augmented-matches Time: 11.02382779121399s\n",
      "get-exact-matches Time: 2.548438787460327s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [16:35, 36.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_1.csv: 22 of 40\n",
      "clean Time: 0.017563581466674805s\n",
      "get-fuzzy-augmented-matches Time: 9.52591586112976s\n",
      "get-exact-matches Time: 2.229552984237671s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [16:55, 31.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_2.csv: 23 of 40\n",
      "clean Time: 0.02166271209716797s\n",
      "get-fuzzy-augmented-matches Time: 9.78259015083313s\n",
      "get-exact-matches Time: 2.5638649463653564s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [17:15, 28.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_3.csv: 24 of 40\n",
      "clean Time: 0.02128124237060547s\n",
      "get-fuzzy-augmented-matches Time: 8.782490968704224s\n",
      "get-exact-matches Time: 2.4410672187805176s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [17:35, 25.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_4.csv: 25 of 40\n",
      "clean Time: 0.017127275466918945s\n",
      "get-fuzzy-augmented-matches Time: 9.017938137054443s\n",
      "get-exact-matches Time: 2.5303893089294434s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [17:54, 23.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_5.csv: 26 of 40\n",
      "clean Time: 0.021183490753173828s\n",
      "get-fuzzy-augmented-matches Time: 9.130558729171753s\n",
      "get-exact-matches Time: 2.5966856479644775s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [18:14, 22.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_6.csv: 27 of 40\n",
      "clean Time: 0.03141283988952637s\n",
      "get-fuzzy-augmented-matches Time: 9.113900184631348s\n",
      "get-exact-matches Time: 2.6176910400390625s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [18:34, 21.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_7.csv: 28 of 40\n",
      "clean Time: 0.021398305892944336s\n",
      "get-fuzzy-augmented-matches Time: 9.244600296020508s\n",
      "get-exact-matches Time: 2.516685724258423s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [18:53, 21.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_8.csv: 29 of 40\n",
      "clean Time: 0.02190399169921875s\n",
      "get-fuzzy-augmented-matches Time: 8.66924262046814s\n",
      "get-exact-matches Time: 2.149139165878296s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29it [19:12, 20.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_9.csv: 30 of 40\n",
      "clean Time: 0.021970272064208984s\n",
      "get-fuzzy-augmented-matches Time: 8.855459451675415s\n",
      "get-exact-matches Time: 2.464099645614624s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [19:31, 20.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_0.csv: 31 of 40\n",
      "clean Time: 0.027716636657714844s\n",
      "get-fuzzy-augmented-matches Time: 5.76170539855957s\n",
      "get-exact-matches Time: 1.264664888381958s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [19:47, 18.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_1.csv: 32 of 40\n",
      "clean Time: 0.027205944061279297s\n",
      "get-fuzzy-augmented-matches Time: 7.109940767288208s\n",
      "get-exact-matches Time: 1.4206857681274414s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [20:04, 18.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_2.csv: 33 of 40\n",
      "clean Time: 0.0270082950592041s\n",
      "get-fuzzy-augmented-matches Time: 6.5825512409210205s\n",
      "get-exact-matches Time: 1.4887146949768066s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33it [20:21, 17.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_3.csv: 34 of 40\n",
      "clean Time: 0.02746415138244629s\n",
      "get-fuzzy-augmented-matches Time: 7.3330769538879395s\n",
      "get-exact-matches Time: 1.473851203918457s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34it [20:38, 17.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_4.csv: 35 of 40\n",
      "clean Time: 0.034212589263916016s\n",
      "get-fuzzy-augmented-matches Time: 6.432801008224487s\n",
      "get-exact-matches Time: 1.3213093280792236s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [20:54, 17.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_5.csv: 36 of 40\n",
      "clean Time: 0.03864479064941406s\n",
      "get-fuzzy-augmented-matches Time: 6.272070646286011s\n",
      "get-exact-matches Time: 1.4125361442565918s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [21:10, 16.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_6.csv: 37 of 40\n",
      "clean Time: 0.031871795654296875s\n",
      "get-fuzzy-augmented-matches Time: 6.169744491577148s\n",
      "get-exact-matches Time: 1.2801506519317627s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "37it [21:26, 16.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_7.csv: 38 of 40\n",
      "clean Time: 0.02163529396057129s\n",
      "get-fuzzy-augmented-matches Time: 6.43291449546814s\n",
      "get-exact-matches Time: 1.7276320457458496s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38it [21:42, 16.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_8.csv: 39 of 40\n",
      "clean Time: 0.02732062339782715s\n",
      "get-fuzzy-augmented-matches Time: 8.29240608215332s\n",
      "get-exact-matches Time: 1.5062415599822998s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39it [22:01, 17.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_9.csv: 40 of 40\n",
      "clean Time: 0.026815176010131836s\n",
      "get-fuzzy-augmented-matches Time: 7.332457542419434s\n",
      "get-exact-matches Time: 1.5170671939849854s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [22:18, 33.47s/it]\n"
     ]
    }
   ],
   "source": [
    "candidate_generation(input_path, output_path, class_count_path, prop_count_path, context_path, graph_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_path = '/data/amandeep/nih-dataset/organization/features'\n",
    "!mkdir -p $features_path\n",
    "classifier_features= ['aligned_pagerank', 'smallest_qnode_number', 'monge_elkan', 'des_cont_jaccard_normalized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_generation(candidate_dir, embedding_dir, class_count_dir, property_count_dir, context_path, output_path):\n",
    "    file_list = glob.glob(candidate_dir + '/*.csv')\n",
    "    for i, file in tqdm(enumerate(file_list)):\n",
    "        filename = file.split('/')[-1]\n",
    "        print(f\"{filename}: {i+1} of {len(file_list)}\")\n",
    "        embedding_file = f\"{embedding_dir}/{filename[:-4]}_graph_embedding_complex.tsv\"\n",
    "        class_count_file = f\"{class_count_dir}/{filename[:-4]}_class_count.tsv\"\n",
    "        property_count_file = f\"{property_count_dir}/{filename[:-4]}_prop_count.tsv\"\n",
    "        context_file = f\"{context_path}/{filename[:-4]}_context.tsv\"\n",
    "        output_file = f\"{output_path}/{filename}\"\n",
    "        if os.path.getsize(file) == 0:\n",
    "                continue\n",
    "        classifier_features_str = \",\".join(classifier_features)\n",
    "        !tl align-page-rank \"$file\" \\\n",
    "            / string-similarity -i --method symmetric_monge_elkan:tokenizer=word -o monge_elkan \\\n",
    "            / string-similarity -i --method symmetric_monge_elkan:tokenizer=word -c label_clean kg_aliases -o monge_elkan_aliases \\\n",
    "            / string-similarity -i --method jaro_winkler -o jaro_winkler \\\n",
    "            / string-similarity -i --method levenshtein -o levenshtein \\\n",
    "            / string-similarity -i --method jaccard:tokenizer=word -c kg_descriptions context -o des_cont_jaccard \\\n",
    "            / normalize-scores -c des_cont_jaccard / smallest-qnode-number \\\n",
    "            / mosaic-features -c kg_labels --num-char --num-tokens \\\n",
    "            / create-singleton-feature -o singleton \\\n",
    "            / vote-by-classifier  \\\n",
    "            --prob-threshold 0.995 \\\n",
    "            --features \"$classifier_features_str\" \\\n",
    "            --model \"$model_file_path\" \\\n",
    "            / score-using-embedding \\\n",
    "            --column-vector-strategy centroid-of-lof \\\n",
    "            --lof-strategy ems-mv \\\n",
    "            -o lof-graph-embedding-score \\\n",
    "            --embedding-file \"$embedding_file\" \\\n",
    "            / generate-reciprocal-rank  \\\n",
    "            -c lof-graph-embedding-score \\\n",
    "            -o lof-reciprocal-rank \\\n",
    "            / compute-tf-idf  \\\n",
    "            --feature-file \"$class_count_file\" \\\n",
    "            --feature-name class_count \\\n",
    "            --singleton-column is_lof \\\n",
    "            -o lof_class_count_tf_idf_score \\\n",
    "            / compute-tf-idf \\\n",
    "            --feature-file \"$property_count_file\" \\\n",
    "            --feature-name property_count \\\n",
    "            --singleton-column is_lof \\\n",
    "            -o lof_property_count_tf_idf_score   > \"$output_file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_0.csv: 1 of 40\n",
      "align-page-rank Time: 1.0750133991241455s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 34.22521376609802s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 60.546825885772705s\n",
      "string-similarity-['jaro_winkler'] Time: 5.3626708984375s\n",
      "string-similarity-['levenshtein'] Time: 42.36357617378235s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 0.8475470542907715s\n",
      "normalize-scores-des_cont_jaccard Time: 0.24726581573486328s\n",
      "smallest-qnode-number Time: 1.79902982711792s\n",
      "mosaic-features Time: 0.11835169792175293s\n",
      "create-singleton-feature Time: 1.5949225425720215s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 1.3775908946990967s\n",
      "Qnodes to lookup: 35492\n",
      "Qnodes from file: 33985\n",
      "_centroid_of_lof: Missing 30 of 814\n",
      "Outlier removal generates 470 lof-voted candidates\n",
      "score-using-embedding Time: 173.3693995475769s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.8407704830169678s\n",
      "compute-tf-idf-class_count Time: 179.989426612854s\n",
      "compute-tf-idf-property_count Time: 182.56513047218323s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [03:07, 187.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_1.csv: 2 of 40\n",
      "align-page-rank Time: 0.9559783935546875s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 27.57402729988098s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 53.09959959983826s\n",
      "string-similarity-['jaro_winkler'] Time: 5.0380518436431885s\n",
      "string-similarity-['levenshtein'] Time: 35.161452293395996s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 0.8215985298156738s\n",
      "normalize-scores-des_cont_jaccard Time: 0.24749255180358887s\n",
      "smallest-qnode-number Time: 1.7863819599151611s\n",
      "mosaic-features Time: 0.11316394805908203s\n",
      "create-singleton-feature Time: 1.3897294998168945s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.7831606864929199s\n",
      "Qnodes to lookup: 34635\n",
      "Qnodes from file: 32936\n",
      "_centroid_of_lof: Missing 102 of 1093\n",
      "Outlier removal generates 595 lof-voted candidates\n",
      "score-using-embedding Time: 147.37474513053894s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.9881770610809326s\n",
      "compute-tf-idf-class_count Time: 153.34168076515198s\n",
      "compute-tf-idf-property_count Time: 156.04862332344055s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [05:49, 172.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_2.csv: 3 of 40\n",
      "align-page-rank Time: 1.070600986480713s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 23.103946208953857s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 42.59343600273132s\n",
      "string-similarity-['jaro_winkler'] Time: 4.423543930053711s\n",
      "string-similarity-['levenshtein'] Time: 30.491483449935913s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 0.8446979522705078s\n",
      "normalize-scores-des_cont_jaccard Time: 0.24195575714111328s\n",
      "smallest-qnode-number Time: 1.7519803047180176s\n",
      "mosaic-features Time: 0.17167115211486816s\n",
      "create-singleton-feature Time: 1.4880199432373047s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.6990902423858643s\n",
      "Qnodes to lookup: 35248\n",
      "Qnodes from file: 33157\n",
      "_centroid_of_lof: Missing 120 of 1197\n",
      "Outlier removal generates 646 lof-voted candidates\n",
      "score-using-embedding Time: 127.51598525047302s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.7980434894561768s\n",
      "compute-tf-idf-class_count Time: 133.2657175064087s\n",
      "compute-tf-idf-property_count Time: 136.0201141834259s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [08:10, 158.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_3.csv: 4 of 40\n",
      "align-page-rank Time: 0.9680442810058594s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 21.39000701904297s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 41.134994983673096s\n",
      "string-similarity-['jaro_winkler'] Time: 4.150817155838013s\n",
      "string-similarity-['levenshtein'] Time: 28.357872009277344s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 0.8551793098449707s\n",
      "normalize-scores-des_cont_jaccard Time: 0.23734736442565918s\n",
      "smallest-qnode-number Time: 2.034531354904175s\n",
      "mosaic-features Time: 0.11067533493041992s\n",
      "create-singleton-feature Time: 1.3285672664642334s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.6594352722167969s\n",
      "Qnodes to lookup: 33091\n",
      "Qnodes from file: 31188\n",
      "_centroid_of_lof: Missing 101 of 1115\n",
      "Outlier removal generates 608 lof-voted candidates\n",
      "score-using-embedding Time: 121.26210594177246s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.8329689502716064s\n",
      "compute-tf-idf-class_count Time: 127.75598788261414s\n",
      "compute-tf-idf-property_count Time: 130.10747599601746s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [10:26, 149.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_4.csv: 5 of 40\n",
      "align-page-rank Time: 0.9781455993652344s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 21.20128846168518s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 39.52588653564453s\n",
      "string-similarity-['jaro_winkler'] Time: 4.184878587722778s\n",
      "string-similarity-['levenshtein'] Time: 27.106751203536987s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 0.8559632301330566s\n",
      "normalize-scores-des_cont_jaccard Time: 0.2433943748474121s\n",
      "smallest-qnode-number Time: 1.778841495513916s\n",
      "mosaic-features Time: 0.11530923843383789s\n",
      "create-singleton-feature Time: 1.3286466598510742s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.6325466632843018s\n",
      "Qnodes to lookup: 34832\n",
      "Qnodes from file: 33084\n",
      "_centroid_of_lof: Missing 85 of 899\n",
      "Outlier removal generates 488 lof-voted candidates\n",
      "score-using-embedding Time: 117.82135605812073s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.7847495079040527s\n",
      "compute-tf-idf-class_count Time: 123.36376118659973s\n",
      "compute-tf-idf-property_count Time: 126.06711888313293s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [12:37, 142.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_5.csv: 6 of 40\n",
      "align-page-rank Time: 0.9485666751861572s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 20.44751787185669s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 40.27610158920288s\n",
      "string-similarity-['jaro_winkler'] Time: 4.276766061782837s\n",
      "string-similarity-['levenshtein'] Time: 27.562937259674072s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 0.8334810733795166s\n",
      "normalize-scores-des_cont_jaccard Time: 0.24446892738342285s\n",
      "smallest-qnode-number Time: 1.7967398166656494s\n",
      "mosaic-features Time: 0.11156368255615234s\n",
      "create-singleton-feature Time: 1.3756847381591797s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.8104357719421387s\n",
      "Qnodes to lookup: 32574\n",
      "Qnodes from file: 30737\n",
      "_centroid_of_lof: Missing 75 of 859\n",
      "Outlier removal generates 470 lof-voted candidates\n",
      "score-using-embedding Time: 118.63994431495667s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.7971489429473877s\n",
      "compute-tf-idf-class_count Time: 124.51496648788452s\n",
      "compute-tf-idf-property_count Time: 127.14037227630615s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [14:50, 139.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_6.csv: 7 of 40\n",
      "align-page-rank Time: 1.0844645500183105s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 18.850862979888916s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 36.245558738708496s\n",
      "string-similarity-['jaro_winkler'] Time: 3.8333394527435303s\n",
      "string-similarity-['levenshtein'] Time: 25.920488834381104s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 0.8268592357635498s\n",
      "normalize-scores-des_cont_jaccard Time: 0.23776888847351074s\n",
      "smallest-qnode-number Time: 1.7251200675964355s\n",
      "mosaic-features Time: 0.11553478240966797s\n",
      "create-singleton-feature Time: 1.5912635326385498s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.730623722076416s\n",
      "Qnodes to lookup: 31939\n",
      "Qnodes from file: 30294\n",
      "_centroid_of_lof: Missing 67 of 654\n",
      "Outlier removal generates 352 lof-voted candidates\n",
      "score-using-embedding Time: 110.799156665802s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.9023318290710449s\n",
      "compute-tf-idf-class_count Time: 116.30188608169556s\n",
      "compute-tf-idf-property_count Time: 118.94547367095947s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [16:54, 134.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_7.csv: 8 of 40\n",
      "align-page-rank Time: 0.9542801380157471s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 19.481122493743896s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 36.679057598114014s\n",
      "string-similarity-['jaro_winkler'] Time: 3.906893253326416s\n",
      "string-similarity-['levenshtein'] Time: 25.867220878601074s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 0.8342502117156982s\n",
      "normalize-scores-des_cont_jaccard Time: 0.2394239902496338s\n",
      "smallest-qnode-number Time: 1.7721357345581055s\n",
      "mosaic-features Time: 0.15809845924377441s\n",
      "create-singleton-feature Time: 1.2859244346618652s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.7135286331176758s\n",
      "Qnodes to lookup: 32346\n",
      "Qnodes from file: 30440\n",
      "_centroid_of_lof: Missing 85 of 835\n",
      "Outlier removal generates 450 lof-voted candidates\n",
      "score-using-embedding Time: 112.17212462425232s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.8177313804626465s\n",
      "compute-tf-idf-class_count Time: 117.95547938346863s\n",
      "compute-tf-idf-property_count Time: 120.38656783103943s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [19:00, 131.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_8.csv: 9 of 40\n",
      "align-page-rank Time: 0.9755654335021973s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 25.655643701553345s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 44.65043377876282s\n",
      "string-similarity-['jaro_winkler'] Time: 4.537208557128906s\n",
      "string-similarity-['levenshtein'] Time: 32.56257343292236s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 0.8307263851165771s\n",
      "normalize-scores-des_cont_jaccard Time: 0.23870229721069336s\n",
      "smallest-qnode-number Time: 1.780503749847412s\n",
      "mosaic-features Time: 0.11252784729003906s\n",
      "create-singleton-feature Time: 1.2868874073028564s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.592646598815918s\n",
      "Qnodes to lookup: 33992\n",
      "Qnodes from file: 32075\n",
      "_centroid_of_lof: Missing 542 of 3490\n",
      "Outlier removal generates 1769 lof-voted candidates\n",
      "score-using-embedding Time: 133.81810855865479s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.8177416324615479s\n",
      "compute-tf-idf-class_count Time: 139.7933099269867s\n",
      "compute-tf-idf-property_count Time: 142.8849549293518s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [21:28, 136.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_9.csv: 10 of 40\n",
      "align-page-rank Time: 0.9385063648223877s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 21.71793031692505s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 39.583229303359985s\n",
      "string-similarity-['jaro_winkler'] Time: 4.22122049331665s\n",
      "string-similarity-['levenshtein'] Time: 29.647648096084595s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 0.8540670871734619s\n",
      "normalize-scores-des_cont_jaccard Time: 0.23522090911865234s\n",
      "smallest-qnode-number Time: 1.7117280960083008s\n",
      "mosaic-features Time: 0.10944533348083496s\n",
      "create-singleton-feature Time: 1.3033437728881836s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.6794722080230713s\n",
      "Qnodes to lookup: 33516\n",
      "Qnodes from file: 31447\n",
      "_centroid_of_lof: Missing 303 of 2034\n",
      "Outlier removal generates 1039 lof-voted candidates\n",
      "score-using-embedding Time: 120.75607991218567s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.8166201114654541s\n",
      "compute-tf-idf-class_count Time: 126.20448803901672s\n",
      "compute-tf-idf-property_count Time: 129.00371527671814s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [23:42, 136.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_0.csv: 11 of 40\n",
      "align-page-rank Time: 1.0573222637176514s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 18.31800413131714s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 27.886035442352295s\n",
      "string-similarity-['jaro_winkler'] Time: 5.283450603485107s\n",
      "string-similarity-['levenshtein'] Time: 19.450575828552246s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 1.5187363624572754s\n",
      "normalize-scores-des_cont_jaccard Time: 0.433239221572876s\n",
      "smallest-qnode-number Time: 1.9124846458435059s\n",
      "mosaic-features Time: 0.20587730407714844s\n",
      "create-singleton-feature Time: 2.334709644317627s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.665135383605957s\n",
      "Qnodes to lookup: 46316\n",
      "Qnodes from file: 45394\n",
      "_centroid_of_lof: Missing 51 of 1234\n",
      "Outlier removal generates 710 lof-voted candidates\n",
      "score-using-embedding Time: 112.89667248725891s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 1.0838372707366943s\n",
      "compute-tf-idf-class_count Time: 123.73420286178589s\n",
      "compute-tf-idf-property_count Time: 128.6895887851715s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [25:57, 135.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_1.csv: 12 of 40\n",
      "align-page-rank Time: 0.9967143535614014s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 16.2237446308136s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 26.921199798583984s\n",
      "string-similarity-['jaro_winkler'] Time: 4.652204513549805s\n",
      "string-similarity-['levenshtein'] Time: 19.140451431274414s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 1.447845458984375s\n",
      "normalize-scores-des_cont_jaccard Time: 0.4280102252960205s\n",
      "smallest-qnode-number Time: 1.9291799068450928s\n",
      "mosaic-features Time: 0.1907360553741455s\n",
      "create-singleton-feature Time: 2.2093942165374756s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.8305025100708008s\n",
      "Qnodes to lookup: 52571\n",
      "Qnodes from file: 51509\n",
      "_centroid_of_lof: Missing 107 of 1679\n",
      "Outlier removal generates 943 lof-voted candidates\n",
      "score-using-embedding Time: 109.11089730262756s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.9560253620147705s\n",
      "compute-tf-idf-class_count Time: 119.43995976448059s\n",
      "compute-tf-idf-property_count Time: 123.94388508796692s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [28:07, 133.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_2.csv: 13 of 40\n",
      "align-page-rank Time: 0.9912090301513672s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 16.4128155708313s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 27.099634408950806s\n",
      "string-similarity-['jaro_winkler'] Time: 4.7454962730407715s\n",
      "string-similarity-['levenshtein'] Time: 18.590408086776733s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 1.442460060119629s\n",
      "normalize-scores-des_cont_jaccard Time: 0.41457104682922363s\n",
      "smallest-qnode-number Time: 2.1308350563049316s\n",
      "mosaic-features Time: 0.19502997398376465s\n",
      "create-singleton-feature Time: 2.117342948913574s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.7718424797058105s\n",
      "Qnodes to lookup: 49648\n",
      "Qnodes from file: 48779\n",
      "_centroid_of_lof: Missing 83 of 1955\n",
      "Outlier removal generates 1123 lof-voted candidates\n",
      "score-using-embedding Time: 107.50864863395691s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 1.181166648864746s\n",
      "compute-tf-idf-class_count Time: 117.99520778656006s\n",
      "compute-tf-idf-property_count Time: 121.72552704811096s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [30:15, 132.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_3.csv: 14 of 40\n",
      "align-page-rank Time: 1.0083098411560059s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 17.265345811843872s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 27.513655424118042s\n",
      "string-similarity-['jaro_winkler'] Time: 4.859482765197754s\n",
      "string-similarity-['levenshtein'] Time: 18.93462896347046s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 1.4107532501220703s\n",
      "normalize-scores-des_cont_jaccard Time: 0.4056735038757324s\n",
      "smallest-qnode-number Time: 2.1586766242980957s\n",
      "mosaic-features Time: 0.19090795516967773s\n",
      "create-singleton-feature Time: 2.221668243408203s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.8132326602935791s\n",
      "Qnodes to lookup: 49692\n",
      "Qnodes from file: 48775\n",
      "_centroid_of_lof: Missing 75 of 1875\n",
      "Outlier removal generates 1080 lof-voted candidates\n",
      "score-using-embedding Time: 108.7851243019104s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.9716954231262207s\n",
      "compute-tf-idf-class_count Time: 118.70809864997864s\n",
      "compute-tf-idf-property_count Time: 122.78529596328735s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [32:24, 131.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_4.csv: 15 of 40\n",
      "align-page-rank Time: 0.9710037708282471s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 15.982155799865723s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 26.879578113555908s\n",
      "string-similarity-['jaro_winkler'] Time: 5.38646388053894s\n",
      "string-similarity-['levenshtein'] Time: 19.012408018112183s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 1.464144229888916s\n",
      "normalize-scores-des_cont_jaccard Time: 0.40741968154907227s\n",
      "smallest-qnode-number Time: 2.1949641704559326s\n",
      "mosaic-features Time: 0.19363856315612793s\n",
      "create-singleton-feature Time: 2.202255964279175s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.8198893070220947s\n",
      "Qnodes to lookup: 52650\n",
      "Qnodes from file: 51640\n",
      "_centroid_of_lof: Missing 81 of 1728\n",
      "Outlier removal generates 988 lof-voted candidates\n",
      "score-using-embedding Time: 108.48448348045349s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.9495508670806885s\n",
      "compute-tf-idf-class_count Time: 118.00812673568726s\n",
      "compute-tf-idf-property_count Time: 122.99070715904236s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [34:33, 130.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_5.csv: 16 of 40\n",
      "align-page-rank Time: 0.9757528305053711s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 16.285701036453247s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 27.736695289611816s\n",
      "string-similarity-['jaro_winkler'] Time: 4.661637306213379s\n",
      "string-similarity-['levenshtein'] Time: 17.938193321228027s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 1.4134094715118408s\n",
      "normalize-scores-des_cont_jaccard Time: 0.4119267463684082s\n",
      "smallest-qnode-number Time: 1.9306418895721436s\n",
      "mosaic-features Time: 0.19400525093078613s\n",
      "create-singleton-feature Time: 2.2346317768096924s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.8670575618743896s\n",
      "Qnodes to lookup: 51939\n",
      "Qnodes from file: 50996\n",
      "_centroid_of_lof: Missing 100 of 1690\n",
      "Outlier removal generates 954 lof-voted candidates\n",
      "score-using-embedding Time: 106.82111072540283s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.9573066234588623s\n",
      "compute-tf-idf-class_count Time: 116.19929814338684s\n",
      "compute-tf-idf-property_count Time: 120.33261275291443s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [36:39, 129.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_6.csv: 17 of 40\n",
      "align-page-rank Time: 1.01318359375s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 16.055179834365845s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 26.911964893341064s\n",
      "string-similarity-['jaro_winkler'] Time: 4.573680639266968s\n",
      "string-similarity-['levenshtein'] Time: 17.504245281219482s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 1.396026611328125s\n",
      "normalize-scores-des_cont_jaccard Time: 0.39748120307922363s\n",
      "smallest-qnode-number Time: 1.888335943222046s\n",
      "mosaic-features Time: 0.18941617012023926s\n",
      "create-singleton-feature Time: 2.179323196411133s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.8543825149536133s\n",
      "Qnodes to lookup: 48906\n",
      "Qnodes from file: 47960\n",
      "_centroid_of_lof: Missing 58 of 1339\n",
      "Outlier removal generates 769 lof-voted candidates\n",
      "score-using-embedding Time: 104.118901014328s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.977102518081665s\n",
      "compute-tf-idf-class_count Time: 113.91616725921631s\n",
      "compute-tf-idf-property_count Time: 118.08891987800598s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [38:43, 127.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_7.csv: 18 of 40\n",
      "align-page-rank Time: 0.9882001876831055s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 15.869466304779053s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 27.015326261520386s\n",
      "string-similarity-['jaro_winkler'] Time: 4.847265005111694s\n",
      "string-similarity-['levenshtein'] Time: 17.750433921813965s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 1.643383264541626s\n",
      "normalize-scores-des_cont_jaccard Time: 0.46599650382995605s\n",
      "smallest-qnode-number Time: 2.453918933868408s\n",
      "mosaic-features Time: 0.19055867195129395s\n",
      "create-singleton-feature Time: 2.03989577293396s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.8721237182617188s\n",
      "Qnodes to lookup: 48616\n",
      "Qnodes from file: 47708\n",
      "_centroid_of_lof: Missing 75 of 1367\n",
      "Outlier removal generates 775 lof-voted candidates\n",
      "score-using-embedding Time: 105.83360362052917s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.9575884342193604s\n",
      "compute-tf-idf-class_count Time: 114.380539894104s\n",
      "compute-tf-idf-property_count Time: 119.32724499702454s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [40:48, 126.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_8.csv: 19 of 40\n",
      "align-page-rank Time: 0.9867458343505859s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 15.925240755081177s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 27.387571811676025s\n",
      "string-similarity-['jaro_winkler'] Time: 4.5482141971588135s\n",
      "string-similarity-['levenshtein'] Time: 17.913103342056274s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 1.3873648643493652s\n",
      "normalize-scores-des_cont_jaccard Time: 0.4158172607421875s\n",
      "smallest-qnode-number Time: 2.493894338607788s\n",
      "mosaic-features Time: 0.18622827529907227s\n",
      "create-singleton-feature Time: 2.1718382835388184s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.9146573543548584s\n",
      "Qnodes to lookup: 48078\n",
      "Qnodes from file: 47047\n",
      "_centroid_of_lof: Missing 411 of 4774\n",
      "Outlier removal generates 2619 lof-voted candidates\n",
      "score-using-embedding Time: 106.95807361602783s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 1.0321979522705078s\n",
      "compute-tf-idf-class_count Time: 116.56032609939575s\n",
      "compute-tf-idf-property_count Time: 121.03604626655579s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [42:55, 126.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_9.csv: 20 of 40\n",
      "align-page-rank Time: 0.9692437648773193s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 16.567383766174316s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 26.56819438934326s\n",
      "string-similarity-['jaro_winkler'] Time: 5.3401405811309814s\n",
      "string-similarity-['levenshtein'] Time: 18.509801626205444s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 1.430771827697754s\n",
      "normalize-scores-des_cont_jaccard Time: 0.4224414825439453s\n",
      "smallest-qnode-number Time: 1.9090683460235596s\n",
      "mosaic-features Time: 0.1721198558807373s\n",
      "create-singleton-feature Time: 2.475177526473999s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.8406307697296143s\n",
      "Qnodes to lookup: 53874\n",
      "Qnodes from file: 52826\n",
      "_centroid_of_lof: Missing 222 of 3041\n",
      "Outlier removal generates 1691 lof-voted candidates\n",
      "score-using-embedding Time: 108.83278179168701s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.9629831314086914s\n",
      "compute-tf-idf-class_count Time: 118.83333039283752s\n",
      "compute-tf-idf-property_count Time: 123.87076759338379s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [45:05, 127.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_0.csv: 21 of 40\n",
      "align-page-rank Time: 0.9773943424224854s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 10.372907161712646s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 20.85562562942505s\n",
      "string-similarity-['jaro_winkler'] Time: 3.6814422607421875s\n",
      "string-similarity-['levenshtein'] Time: 8.088920593261719s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 1.5912425518035889s\n",
      "normalize-scores-des_cont_jaccard Time: 0.4352710247039795s\n",
      "smallest-qnode-number Time: 2.107914686203003s\n",
      "mosaic-features Time: 0.2822556495666504s\n",
      "create-singleton-feature Time: 2.9430036544799805s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.8968322277069092s\n",
      "Qnodes to lookup: 9982\n",
      "Qnodes from file: 9715\n",
      "Outlier removal generates 298 lof-voted candidates\n",
      "score-using-embedding Time: 86.42095184326172s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 1.1488852500915527s\n",
      "compute-tf-idf-class_count Time: 96.19055795669556s\n",
      "compute-tf-idf-property_count Time: 100.71248459815979s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [46:52, 121.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_1.csv: 22 of 40\n",
      "align-page-rank Time: 1.027571439743042s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 10.489678621292114s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 19.743183851242065s\n",
      "string-similarity-['jaro_winkler'] Time: 3.6698548793792725s\n",
      "string-similarity-['levenshtein'] Time: 7.7189905643463135s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 1.5717785358428955s\n",
      "normalize-scores-des_cont_jaccard Time: 0.40588974952697754s\n",
      "smallest-qnode-number Time: 2.301467180252075s\n",
      "mosaic-features Time: 0.2145547866821289s\n",
      "create-singleton-feature Time: 2.8144824504852295s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.7012887001037598s\n",
      "Qnodes to lookup: 10359\n",
      "Qnodes from file: 10077\n",
      "Outlier removal generates 431 lof-voted candidates\n",
      "score-using-embedding Time: 83.4658727645874s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.9879591464996338s\n",
      "compute-tf-idf-class_count Time: 92.82403898239136s\n",
      "compute-tf-idf-property_count Time: 97.53423738479614s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [48:36, 116.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_2.csv: 23 of 40\n",
      "align-page-rank Time: 1.007856845855713s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 10.298721551895142s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 20.2051043510437s\n",
      "string-similarity-['jaro_winkler'] Time: 3.92425537109375s\n",
      "string-similarity-['levenshtein'] Time: 7.636511325836182s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 1.773076057434082s\n",
      "normalize-scores-des_cont_jaccard Time: 0.4129362106323242s\n",
      "smallest-qnode-number Time: 2.0393261909484863s\n",
      "mosaic-features Time: 0.21813607215881348s\n",
      "create-singleton-feature Time: 3.026293992996216s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.7742204666137695s\n",
      "Qnodes to lookup: 10432\n",
      "Qnodes from file: 10147\n",
      "Outlier removal generates 244 lof-voted candidates\n",
      "score-using-embedding Time: 83.7257878780365s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.9686839580535889s\n",
      "compute-tf-idf-class_count Time: 93.07697892189026s\n",
      "compute-tf-idf-property_count Time: 97.52963876724243s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [50:19, 112.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_3.csv: 24 of 40\n",
      "align-page-rank Time: 0.9869875907897949s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 10.396312236785889s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 19.645426750183105s\n",
      "string-similarity-['jaro_winkler'] Time: 3.5934629440307617s\n",
      "string-similarity-['levenshtein'] Time: 7.673677682876587s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 1.5204963684082031s\n",
      "normalize-scores-des_cont_jaccard Time: 0.4204103946685791s\n",
      "smallest-qnode-number Time: 1.9214038848876953s\n",
      "mosaic-features Time: 0.21980929374694824s\n",
      "create-singleton-feature Time: 2.490551710128784s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.756756067276001s\n",
      "Qnodes to lookup: 9069\n",
      "Qnodes from file: 8815\n",
      "Outlier removal generates 374 lof-voted candidates\n",
      "score-using-embedding Time: 82.23032450675964s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.9849913120269775s\n",
      "compute-tf-idf-class_count Time: 91.77732872962952s\n",
      "compute-tf-idf-property_count Time: 96.06878280639648s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [52:02, 109.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_4.csv: 25 of 40\n",
      "align-page-rank Time: 1.0070891380310059s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 10.36080551147461s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 20.244444608688354s\n",
      "string-similarity-['jaro_winkler'] Time: 3.6728451251983643s\n",
      "string-similarity-['levenshtein'] Time: 7.906152963638306s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 1.537628412246704s\n",
      "normalize-scores-des_cont_jaccard Time: 0.4151942729949951s\n",
      "smallest-qnode-number Time: 1.9152886867523193s\n",
      "mosaic-features Time: 0.2214653491973877s\n",
      "create-singleton-feature Time: 2.5282199382781982s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.7281317710876465s\n",
      "Qnodes to lookup: 9672\n",
      "Qnodes from file: 9405\n",
      "Outlier removal generates 436 lof-voted candidates\n",
      "score-using-embedding Time: 84.2214343547821s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 1.1451067924499512s\n",
      "compute-tf-idf-class_count Time: 94.26185488700867s\n",
      "compute-tf-idf-property_count Time: 98.82797908782959s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [53:47, 108.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_5.csv: 26 of 40\n",
      "align-page-rank Time: 0.9982004165649414s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 10.354867935180664s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 20.223699808120728s\n",
      "string-similarity-['jaro_winkler'] Time: 3.934480667114258s\n",
      "string-similarity-['levenshtein'] Time: 8.531984329223633s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 1.5378735065460205s\n",
      "normalize-scores-des_cont_jaccard Time: 0.41260766983032227s\n",
      "smallest-qnode-number Time: 2.0926058292388916s\n",
      "mosaic-features Time: 0.22326898574829102s\n",
      "create-singleton-feature Time: 2.396209716796875s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 1.7350029945373535s\n",
      "Qnodes to lookup: 9162\n",
      "Qnodes from file: 8912\n",
      "_centroid_of_lof: Missing 1 of 546\n",
      "Outlier removal generates 445 lof-voted candidates\n",
      "score-using-embedding Time: 85.26600432395935s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.9734196662902832s\n",
      "compute-tf-idf-class_count Time: 94.81391620635986s\n",
      "compute-tf-idf-property_count Time: 99.28266310691833s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [55:32, 107.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_6.csv: 27 of 40\n",
      "align-page-rank Time: 1.042668104171753s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 10.428284168243408s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 20.1690411567688s\n",
      "string-similarity-['jaro_winkler'] Time: 3.7859716415405273s\n",
      "string-similarity-['levenshtein'] Time: 8.241723775863647s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 1.5737419128417969s\n",
      "normalize-scores-des_cont_jaccard Time: 0.42809534072875977s\n",
      "smallest-qnode-number Time: 1.9183526039123535s\n",
      "mosaic-features Time: 0.22122907638549805s\n",
      "create-singleton-feature Time: 2.5017616748809814s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.6486265659332275s\n",
      "Qnodes to lookup: 9328\n",
      "Qnodes from file: 9090\n",
      "Outlier removal generates 437 lof-voted candidates\n",
      "score-using-embedding Time: 83.77024173736572s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 1.0175490379333496s\n",
      "compute-tf-idf-class_count Time: 94.10895466804504s\n",
      "compute-tf-idf-property_count Time: 98.52270913124084s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [57:20, 107.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_7.csv: 28 of 40\n",
      "align-page-rank Time: 1.0164411067962646s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 11.005845069885254s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 20.4557523727417s\n",
      "string-similarity-['jaro_winkler'] Time: 3.7629635334014893s\n",
      "string-similarity-['levenshtein'] Time: 8.41431212425232s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 1.7634539604187012s\n",
      "normalize-scores-des_cont_jaccard Time: 0.4176468849182129s\n",
      "smallest-qnode-number Time: 1.9592900276184082s\n",
      "mosaic-features Time: 0.2642476558685303s\n",
      "create-singleton-feature Time: 2.8491127490997314s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.7009799480438232s\n",
      "Qnodes to lookup: 8934\n",
      "Qnodes from file: 8695\n",
      "Outlier removal generates 438 lof-voted candidates\n",
      "score-using-embedding Time: 86.69547390937805s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.9981646537780762s\n",
      "compute-tf-idf-class_count Time: 95.97393441200256s\n",
      "compute-tf-idf-property_count Time: 100.56166505813599s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [59:07, 107.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_8.csv: 29 of 40\n",
      "align-page-rank Time: 0.9828195571899414s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 8.614214897155762s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 16.684813737869263s\n",
      "string-similarity-['jaro_winkler'] Time: 3.337986946105957s\n",
      "string-similarity-['levenshtein'] Time: 6.406893253326416s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 1.2936913967132568s\n",
      "normalize-scores-des_cont_jaccard Time: 0.3452444076538086s\n",
      "smallest-qnode-number Time: 1.8376729488372803s\n",
      "mosaic-features Time: 0.22709083557128906s\n",
      "create-singleton-feature Time: 2.417585849761963s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.8362329006195068s\n",
      "Qnodes to lookup: 9788\n",
      "Qnodes from file: 9532\n",
      "Outlier removal generates 327 lof-voted candidates\n",
      "score-using-embedding Time: 70.38600516319275s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.9566497802734375s\n",
      "compute-tf-idf-class_count Time: 78.31398391723633s\n",
      "compute-tf-idf-property_count Time: 81.81538891792297s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29it [1:00:35, 101.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_9.csv: 30 of 40\n",
      "align-page-rank Time: 1.0083086490631104s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 9.319494009017944s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 18.391188621520996s\n",
      "string-similarity-['jaro_winkler'] Time: 3.7086360454559326s\n",
      "string-similarity-['levenshtein'] Time: 7.4245171546936035s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 1.703660488128662s\n",
      "normalize-scores-des_cont_jaccard Time: 0.40096521377563477s\n",
      "smallest-qnode-number Time: 2.136570692062378s\n",
      "mosaic-features Time: 0.20950841903686523s\n",
      "create-singleton-feature Time: 2.246825695037842s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.8680691719055176s\n",
      "Qnodes to lookup: 9270\n",
      "Qnodes from file: 9017\n",
      "Outlier removal generates 106 lof-voted candidates\n",
      "score-using-embedding Time: 79.54322075843811s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.96329665184021s\n",
      "compute-tf-idf-class_count Time: 89.00326251983643s\n",
      "compute-tf-idf-property_count Time: 92.75247192382812s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [1:02:14, 100.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_0.csv: 31 of 40\n",
      "align-page-rank Time: 1.005408525466919s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 71.51389217376709s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 153.793771982193s\n",
      "string-similarity-['jaro_winkler'] Time: 13.104278802871704s\n",
      "string-similarity-['levenshtein'] Time: 78.44478440284729s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 1.5445148944854736s\n",
      "normalize-scores-des_cont_jaccard Time: 0.4132075309753418s\n",
      "smallest-qnode-number Time: 1.889674425125122s\n",
      "mosaic-features Time: 0.295076847076416s\n",
      "create-singleton-feature Time: 2.553874969482422s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.7522153854370117s\n",
      "Qnodes to lookup: 2782\n",
      "Qnodes from file: 2724\n",
      "_centroid_of_lof: Missing 58 of 1050\n",
      "Outlier removal generates 595 lof-voted candidates\n",
      "score-using-embedding Time: 362.88651633262634s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.9698855876922607s\n",
      "compute-tf-idf-class_count Time: 372.99128556251526s\n",
      "compute-tf-idf-property_count Time: 378.0231912136078s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [1:08:38, 185.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_1.csv: 32 of 40\n",
      "align-page-rank Time: 1.0876317024230957s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 69.92683219909668s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 151.65000653266907s\n",
      "string-similarity-['jaro_winkler'] Time: 13.033940076828003s\n",
      "string-similarity-['levenshtein'] Time: 80.05111241340637s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 1.741365909576416s\n",
      "normalize-scores-des_cont_jaccard Time: 0.4036722183227539s\n",
      "smallest-qnode-number Time: 1.914891004562378s\n",
      "mosaic-features Time: 0.23042702674865723s\n",
      "create-singleton-feature Time: 2.8283557891845703s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 1.8110120296478271s\n",
      "Qnodes to lookup: 4955\n",
      "Qnodes from file: 4840\n",
      "_centroid_of_lof: Missing 96 of 1621\n",
      "Outlier removal generates 915 lof-voted candidates\n",
      "score-using-embedding Time: 363.9993929862976s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.9622275829315186s\n",
      "compute-tf-idf-class_count Time: 374.5683045387268s\n",
      "compute-tf-idf-property_count Time: 379.7963516712189s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [1:15:04, 245.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_2.csv: 33 of 40\n",
      "align-page-rank Time: 1.0458261966705322s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 68.26721858978271s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 149.9673306941986s\n",
      "string-similarity-['jaro_winkler'] Time: 13.29618787765503s\n",
      "string-similarity-['levenshtein'] Time: 80.79345774650574s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 1.6632800102233887s\n",
      "normalize-scores-des_cont_jaccard Time: 0.4608423709869385s\n",
      "smallest-qnode-number Time: 1.9873237609863281s\n",
      "mosaic-features Time: 0.29924559593200684s\n",
      "create-singleton-feature Time: 2.737806558609009s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 2.003826379776001s\n",
      "Qnodes to lookup: 4882\n",
      "Qnodes from file: 4781\n",
      "_centroid_of_lof: Missing 109 of 1931\n",
      "Outlier removal generates 1093 lof-voted candidates\n",
      "score-using-embedding Time: 361.9149696826935s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.989680290222168s\n",
      "compute-tf-idf-class_count Time: 372.5349838733673s\n",
      "compute-tf-idf-property_count Time: 377.4405596256256s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33it [1:21:36, 289.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_3.csv: 34 of 40\n",
      "align-page-rank Time: 0.970714807510376s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 68.07570433616638s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 151.56164073944092s\n",
      "string-similarity-['jaro_winkler'] Time: 12.652451992034912s\n",
      "string-similarity-['levenshtein'] Time: 78.57598996162415s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 1.5696561336517334s\n",
      "normalize-scores-des_cont_jaccard Time: 0.4479207992553711s\n",
      "smallest-qnode-number Time: 2.2006454467773438s\n",
      "mosaic-features Time: 0.23843121528625488s\n",
      "create-singleton-feature Time: 2.5543575286865234s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.789085865020752s\n",
      "Qnodes to lookup: 5822\n",
      "Qnodes from file: 5664\n",
      "_centroid_of_lof: Missing 139 of 1860\n",
      "Outlier removal generates 1033 lof-voted candidates\n",
      "score-using-embedding Time: 358.82942748069763s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.9851958751678467s\n",
      "compute-tf-idf-class_count Time: 369.1953582763672s\n",
      "compute-tf-idf-property_count Time: 374.4716773033142s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34it [1:27:59, 317.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_4.csv: 35 of 40\n",
      "align-page-rank Time: 0.9604651927947998s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 68.8801589012146s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 149.3949375152588s\n",
      "string-similarity-['jaro_winkler'] Time: 12.705446243286133s\n",
      "string-similarity-['levenshtein'] Time: 80.4415442943573s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 1.5469698905944824s\n",
      "normalize-scores-des_cont_jaccard Time: 0.4033503532409668s\n",
      "smallest-qnode-number Time: 1.9382994174957275s\n",
      "mosaic-features Time: 0.3001687526702881s\n",
      "create-singleton-feature Time: 2.8490023612976074s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.7552905082702637s\n",
      "Qnodes to lookup: 4287\n",
      "Qnodes from file: 4173\n",
      "_centroid_of_lof: Missing 107 of 1832\n",
      "Outlier removal generates 1035 lof-voted candidates\n",
      "score-using-embedding Time: 360.1274127960205s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.9541661739349365s\n",
      "compute-tf-idf-class_count Time: 369.89387130737305s\n",
      "compute-tf-idf-property_count Time: 374.85849499702454s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [1:34:20, 336.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_5.csv: 36 of 40\n",
      "align-page-rank Time: 0.9989457130432129s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 69.25024938583374s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 149.36655712127686s\n",
      "string-similarity-['jaro_winkler'] Time: 13.158967733383179s\n",
      "string-similarity-['levenshtein'] Time: 79.98825335502625s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 1.5624144077301025s\n",
      "normalize-scores-des_cont_jaccard Time: 0.40759825706481934s\n",
      "smallest-qnode-number Time: 1.9363396167755127s\n",
      "mosaic-features Time: 0.3013439178466797s\n",
      "create-singleton-feature Time: 2.4601247310638428s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 1.1176466941833496s\n",
      "Qnodes to lookup: 3986\n",
      "Qnodes from file: 3889\n",
      "_centroid_of_lof: Missing 94 of 1628\n",
      "Outlier removal generates 920 lof-voted candidates\n",
      "score-using-embedding Time: 356.68072962760925s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.9948852062225342s\n",
      "compute-tf-idf-class_count Time: 367.9118103981018s\n",
      "compute-tf-idf-property_count Time: 373.2298948764801s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [1:40:40, 349.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_6.csv: 37 of 40\n",
      "align-page-rank Time: 0.9666447639465332s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 71.38448691368103s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 158.45361137390137s\n",
      "string-similarity-['jaro_winkler'] Time: 13.920427322387695s\n",
      "string-similarity-['levenshtein'] Time: 80.0201735496521s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 1.5579187870025635s\n",
      "normalize-scores-des_cont_jaccard Time: 0.40819621086120605s\n",
      "smallest-qnode-number Time: 1.8885338306427002s\n",
      "mosaic-features Time: 0.30228662490844727s\n",
      "create-singleton-feature Time: 2.7536470890045166s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.8426344394683838s\n",
      "Qnodes to lookup: 4262\n",
      "Qnodes from file: 4192\n",
      "_centroid_of_lof: Missing 46 of 968\n",
      "Outlier removal generates 553 lof-voted candidates\n",
      "score-using-embedding Time: 371.0001118183136s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.9828605651855469s\n",
      "compute-tf-idf-class_count Time: 381.87881422042847s\n",
      "compute-tf-idf-property_count Time: 387.13680815696716s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "37it [1:47:14, 363.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_7.csv: 38 of 40\n",
      "align-page-rank Time: 0.9567022323608398s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 71.29396724700928s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 153.96324944496155s\n",
      "string-similarity-['jaro_winkler'] Time: 12.853589057922363s\n",
      "string-similarity-['levenshtein'] Time: 79.8963475227356s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 1.5176613330841064s\n",
      "normalize-scores-des_cont_jaccard Time: 0.4012172222137451s\n",
      "smallest-qnode-number Time: 1.9884123802185059s\n",
      "mosaic-features Time: 0.2955818176269531s\n",
      "create-singleton-feature Time: 2.434213161468506s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 1.7708020210266113s\n",
      "Qnodes to lookup: 3726\n",
      "Qnodes from file: 3630\n",
      "_centroid_of_lof: Missing 83 of 1276\n",
      "Outlier removal generates 716 lof-voted candidates\n",
      "score-using-embedding Time: 365.863094329834s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.9690451622009277s\n",
      "compute-tf-idf-class_count Time: 375.6534779071808s\n",
      "compute-tf-idf-property_count Time: 380.8504936695099s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38it [1:53:42, 370.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_8.csv: 39 of 40\n",
      "align-page-rank Time: 1.0018589496612549s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 61.890140533447266s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 130.56145191192627s\n",
      "string-similarity-['jaro_winkler'] Time: 11.904874324798584s\n",
      "string-similarity-['levenshtein'] Time: 71.60157465934753s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 1.7614617347717285s\n",
      "normalize-scores-des_cont_jaccard Time: 0.39958667755126953s\n",
      "smallest-qnode-number Time: 2.393639087677002s\n",
      "mosaic-features Time: 0.28822803497314453s\n",
      "create-singleton-feature Time: 2.805938243865967s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 1.7723073959350586s\n",
      "Qnodes to lookup: 7701\n",
      "Qnodes from file: 7458\n",
      "_centroid_of_lof: Missing 478 of 6086\n",
      "Outlier removal generates 3365 lof-voted candidates\n",
      "score-using-embedding Time: 327.4672396183014s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.9420521259307861s\n",
      "compute-tf-idf-class_count Time: 336.2871313095093s\n",
      "compute-tf-idf-property_count Time: 341.5487148761749s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39it [1:59:33, 364.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_9.csv: 40 of 40\n",
      "align-page-rank Time: 1.0586178302764893s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 67.3774425983429s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 142.59416317939758s\n",
      "string-similarity-['jaro_winkler'] Time: 12.160614013671875s\n",
      "string-similarity-['levenshtein'] Time: 76.88030791282654s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 1.7703096866607666s\n",
      "normalize-scores-des_cont_jaccard Time: 0.406919002532959s\n",
      "smallest-qnode-number Time: 1.8648591041564941s\n",
      "mosaic-features Time: 0.2920200824737549s\n",
      "create-singleton-feature Time: 3.3149168491363525s\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.7969043254852295s\n",
      "Qnodes to lookup: 7341\n",
      "Qnodes from file: 7117\n",
      "_centroid_of_lof: Missing 290 of 3444\n",
      "Outlier removal generates 1897 lof-voted candidates\n",
      "score-using-embedding Time: 346.1379041671753s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 1.1644363403320312s\n",
      "compute-tf-idf-class_count Time: 357.21888852119446s\n",
      "compute-tf-idf-property_count Time: 362.1715130805969s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [2:05:45, 188.63s/it]\n"
     ]
    }
   ],
   "source": [
    "feature_generation(output_path, graph_embedding, class_count_path, prop_count_path, context_path, features_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_files(i_path, output_file, sep=None):\n",
    "    df_l = []\n",
    "    for f in glob.glob(f'{i_path}/*'):\n",
    "        if sep:\n",
    "            df_l.append(pd.read_csv(f, sep=sep))\n",
    "        else:\n",
    "            df_l.append(pd.read_csv(f))\n",
    "    if sep:\n",
    "        pd.concat(df_l).to_csv(output_file, index=False, sep=sep)\n",
    "    else:\n",
    "        pd.concat(df_l).to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_context_match(features_path, context_path, custom_file, output_path):\n",
    "    file_list = glob.glob(features_path + '/*.csv')\n",
    "    for i, f in tqdm(enumerate(file_list)):\n",
    "        if i > -1:\n",
    "            f_name = f.split('/')[-1]\n",
    "            print(f'{f_name}: {i+1} of {len(file_list)}')\n",
    "            context_file = f\"{context_path}/{f_name[:-4]}_context.tsv\"\n",
    "            output_file = f\"{output_path}/{f_name}\"\n",
    "            !tl context-match --custom-context-file $custom_file \\\n",
    "            --context-file $context_file --string-separator \";\" \\\n",
    "            --similarity-string-threshold $string_threshold $f > $output_file\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_path = '/data/amandeep/nih-dataset/organization/temp/context'\n",
    "features_path = '/data/amandeep/nih-dataset/organization/features'\n",
    "context_output_path = '/data/amandeep/nih-dataset/organization/features_with_context'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_0.csv: 1 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [08:55, 535.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_1.csv: 2 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [17:29, 523.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_2.csv: 3 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [25:47, 511.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_3.csv: 4 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [33:52, 501.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_4.csv: 5 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [42:15, 501.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_5.csv: 6 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [50:25, 497.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_6.csv: 7 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [58:40, 496.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_7.csv: 8 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [1:06:40, 491.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_8.csv: 9 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [1:14:15, 480.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_9.csv: 10 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [1:21:54, 473.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_0.csv: 11 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [1:54:23, 924.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_1.csv: 12 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [2:22:01, 1148.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_2.csv: 13 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [2:50:50, 1324.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_3.csv: 14 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [3:18:33, 1426.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_4.csv: 15 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [3:46:47, 1507.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_5.csv: 16 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [4:14:04, 1546.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_6.csv: 17 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [4:40:30, 1558.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_7.csv: 18 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [5:08:59, 1603.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_8.csv: 19 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [5:34:20, 1578.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_9.csv: 20 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [6:02:30, 1612.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_0.csv: 21 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [6:37:42, 1762.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_1.csv: 22 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [7:11:16, 1837.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_2.csv: 23 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [7:43:54, 1873.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_3.csv: 24 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [8:16:48, 1903.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_4.csv: 25 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [8:50:23, 1937.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_5.csv: 26 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [9:23:28, 1951.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_6.csv: 27 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [9:58:24, 1994.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_7.csv: 28 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [10:33:25, 2026.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_8.csv: 29 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29it [10:55:36, 1818.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_9.csv: 30 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [11:24:30, 1792.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_0.csv: 31 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [11:56:16, 1826.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_1.csv: 32 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [12:27:33, 1841.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_2.csv: 33 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33it [12:58:28, 1845.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_3.csv: 34 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34it [13:28:52, 1839.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_4.csv: 35 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [13:59:57, 1847.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_5.csv: 36 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [14:30:52, 1849.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_6.csv: 37 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "37it [15:01:25, 1844.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_7.csv: 38 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38it [15:31:38, 1835.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_8.csv: 39 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39it [15:59:44, 1790.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_9.csv: 40 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [16:29:43, 1484.60s/it]\n"
     ]
    }
   ],
   "source": [
    "run_context_match(features_path, context_path, '/data/amandeep/nih-dataset/coauthors.context.tsv.gz', context_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_path = '/data/amandeep/nih-dataset/organization/predictions'\n",
    "!mkdir -p $prediction_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_str = \",\".join(features)\n",
    "def run_prediction(features_path, prediction_path):\n",
    "    file_list = glob.glob(features_path + '/*.csv')\n",
    "    for i, f in tqdm(enumerate(file_list)):\n",
    "        f_name = f.split('/')[-1]\n",
    "        print(f'{f_name}: {i+1} of {len(file_list)}')\n",
    "        output_file = f\"{prediction_path}/{f_name}\"\n",
    "        !tl predict-using-model -o siamese_prediction \\\n",
    "        --ranking-model $ranking_model_file_path \\\n",
    "        --features $features_str \\\n",
    "        --normalization-factor $min_max_scaler_path $f > $output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_0.csv: 1 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.797147989273071s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:10, 10.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_1.csv: 2 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.323748350143433s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:20,  9.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_2.csv: 3 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.141092538833618s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:29,  9.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_3.csv: 4 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.062241554260254s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:38,  9.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_4.csv: 5 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.240553379058838s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:48,  9.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_5.csv: 6 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.036336898803711s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:57,  9.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_6.csv: 7 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.240834712982178s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [01:06,  9.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_7.csv: 8 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.141998291015625s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [01:16,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_8.csv: 9 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.2000837326049805s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [01:25,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_9.csv: 10 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.21091628074646s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [01:34,  9.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_0.csv: 11 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.49596905708313s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [01:46, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_1.csv: 12 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.288828611373901s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [01:57, 10.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_2.csv: 13 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 5.0411858558654785s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [02:09, 10.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_3.csv: 14 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.6633217334747314s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [02:21, 11.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_4.csv: 15 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.735842704772949s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [02:33, 11.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_5.csv: 16 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.329231023788452s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [02:44, 11.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_6.csv: 17 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.514092445373535s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [02:55, 11.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_7.csv: 18 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.644038438796997s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [03:07, 11.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_8.csv: 19 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.527430534362793s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [03:19, 11.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_9.csv: 20 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.2891685962677s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [03:30, 11.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_0.csv: 21 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.419566869735718s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [03:42, 11.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_1.csv: 22 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.513932228088379s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [03:53, 11.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_2.csv: 23 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.778185844421387s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [04:06, 11.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_3.csv: 24 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.97555136680603s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [04:18, 11.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_4.csv: 25 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.743338584899902s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [04:29, 11.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_5.csv: 26 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.858398914337158s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [04:41, 11.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_6.csv: 27 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.796367645263672s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [04:54, 12.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_7.csv: 28 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.876089811325073s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [05:06, 11.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_8.csv: 29 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.336930751800537s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29it [05:16, 11.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_9.csv: 30 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.520034313201904s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [05:28, 11.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_0.csv: 31 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.332199811935425s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [05:40, 11.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_1.csv: 32 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.4243903160095215s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [05:52, 11.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_2.csv: 33 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.572021007537842s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33it [06:04, 11.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_3.csv: 34 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.807182788848877s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34it [06:16, 11.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_4.csv: 35 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.282679080963135s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [06:28, 12.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_5.csv: 36 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.642938852310181s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [06:41, 12.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_6.csv: 37 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.646281480789185s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "37it [06:53, 12.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_7.csv: 38 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.777512311935425s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38it [07:06, 12.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_8.csv: 39 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.266456842422485s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39it [07:17, 12.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_9.csv: 40 of 40\n",
      "/data/amandeep/github/table-linker/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 4.788407325744629s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [07:29, 11.24s/it]\n"
     ]
    }
   ],
   "source": [
    "run_prediction(context_output_path, prediction_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorized_path = '/data/amandeep/nih-dataset/organization/colorized'\n",
    "!mkdir -p $colorized_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_color(prediction_path, colorized_path):\n",
    "    file_list = glob.glob(prediction_path + '/*.csv')\n",
    "    for i, f in tqdm(enumerate(file_list)):\n",
    "        f_name = f.split('/')[-1]\n",
    "        print(f'{f_name}: {i+1} of {len(file_list)}')\n",
    "        output_file = f\"{colorized_path}/{f_name[:-4]}.xlsx\"\n",
    "        !tl get-kg-links -c $final_score_column -k 5 --k-rows $f \\\n",
    "        / add-color -c \"$final_score_column\" -k 5 --output \"$output_file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_0.csv: 1 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.5695652961730957s\n",
      "add-color Time: 0.9500653743743896s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:10, 10.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_1.csv: 2 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.1562962532043457s\n",
      "add-color Time: 0.8754355907440186s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:19,  9.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_2.csv: 3 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.1087517738342285s\n",
      "add-color Time: 0.8810536861419678s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:29,  9.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_3.csv: 4 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.0367207527160645s\n",
      "add-color Time: 0.8764631748199463s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:38,  9.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_4.csv: 5 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.174614191055298s\n",
      "add-color Time: 0.852297306060791s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:48,  9.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_5.csv: 6 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.5338332653045654s\n",
      "add-color Time: 0.8408055305480957s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:57,  9.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_6.csv: 7 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.0713090896606445s\n",
      "add-color Time: 0.8683221340179443s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [01:07,  9.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_7.csv: 8 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.146402359008789s\n",
      "add-color Time: 0.8479042053222656s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [01:16,  9.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_8.csv: 9 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.070218324661255s\n",
      "add-color Time: 0.8730368614196777s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [01:26,  9.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_9.csv: 10 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.4023256301879883s\n",
      "add-color Time: 0.867779016494751s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [01:35,  9.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_0.csv: 11 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.4714574813842773s\n",
      "add-color Time: 0.8327503204345703s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [01:46,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_1.csv: 12 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.4646682739257812s\n",
      "add-color Time: 0.8299241065979004s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [01:56,  9.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_2.csv: 13 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.4258387088775635s\n",
      "add-color Time: 0.8433747291564941s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [02:06, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_3.csv: 14 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.34476375579834s\n",
      "add-color Time: 0.8604891300201416s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [02:17, 10.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_4.csv: 15 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.3901212215423584s\n",
      "add-color Time: 0.8506553173065186s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [02:27, 10.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_5.csv: 16 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.4789376258850098s\n",
      "add-color Time: 0.8505980968475342s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [02:37, 10.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_6.csv: 17 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.927231788635254s\n",
      "add-color Time: 0.8532097339630127s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [02:48, 10.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_7.csv: 18 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.596982717514038s\n",
      "add-color Time: 0.8506174087524414s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [02:58, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_8.csv: 19 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.414686679840088s\n",
      "add-color Time: 0.8181829452514648s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [03:08, 10.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_9.csv: 20 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.418820381164551s\n",
      "add-color Time: 0.9064044952392578s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [03:19, 10.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_0.csv: 21 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.4765284061431885s\n",
      "add-color Time: 0.8239572048187256s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [03:29, 10.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_1.csv: 22 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.4405221939086914s\n",
      "add-color Time: 0.8213872909545898s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [03:39, 10.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_2.csv: 23 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.8976736068725586s\n",
      "add-color Time: 0.8087537288665771s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [03:50, 10.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_3.csv: 24 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.4199416637420654s\n",
      "add-color Time: 0.8317258358001709s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [04:01, 10.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_4.csv: 25 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.3803727626800537s\n",
      "add-color Time: 0.8288850784301758s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [04:11, 10.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_5.csv: 26 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.594879388809204s\n",
      "add-color Time: 0.8140954971313477s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [04:21, 10.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_6.csv: 27 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.575378179550171s\n",
      "add-color Time: 0.7958765029907227s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [04:32, 10.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_7.csv: 28 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.3726232051849365s\n",
      "add-color Time: 0.8033864498138428s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [04:43, 10.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_8.csv: 29 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.2376821041107178s\n",
      "add-color Time: 0.7221157550811768s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29it [04:53, 10.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_9.csv: 30 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.4694011211395264s\n",
      "add-color Time: 0.6996941566467285s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [05:02, 10.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_0.csv: 31 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.3562047481536865s\n",
      "add-color Time: 0.8355593681335449s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [05:13, 10.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_1.csv: 32 of 40\n",
      "get-kg-links-siamese_prediction Time: 4.069069147109985s\n",
      "add-color Time: 0.8135066032409668s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [05:24, 10.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_2.csv: 33 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.4110913276672363s\n",
      "add-color Time: 0.8383035659790039s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33it [05:33, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_3.csv: 34 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.738407850265503s\n",
      "add-color Time: 0.8228514194488525s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34it [05:44, 10.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_4.csv: 35 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.3720908164978027s\n",
      "add-color Time: 0.8112969398498535s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [05:54, 10.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_5.csv: 36 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.6143009662628174s\n",
      "add-color Time: 0.7425711154937744s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [06:05, 10.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_6.csv: 37 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.886761426925659s\n",
      "add-color Time: 0.7476999759674072s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "37it [06:15, 10.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_7.csv: 38 of 40\n",
      "get-kg-links-siamese_prediction Time: 4.106557607650757s\n",
      "add-color Time: 0.858238697052002s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38it [06:26, 10.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_8.csv: 39 of 40\n",
      "get-kg-links-siamese_prediction Time: 4.09746527671814s\n",
      "add-color Time: 0.8207793235778809s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39it [06:38, 10.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_9.csv: 40 of 40\n",
      "get-kg-links-siamese_prediction Time: 3.471024513244629s\n",
      "add-color Time: 0.7944426536560059s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [06:48, 10.20s/it]\n"
     ]
    }
   ],
   "source": [
    "topk_color(prediction_path, colorized_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_NILS(colorized_path, output_path):\n",
    "    file_list = glob.glob(colorized_path + '/*.xlsx')\n",
    "    for i, f in tqdm(enumerate(file_list)):\n",
    "        f_name = f.split('/')[-1]\n",
    "        print(f'{f_name}: {i+1} of {len(file_list)}')\n",
    "        output_file = f\"{output_path}/{f_name[:-5]}.csv\"\n",
    "        \n",
    "        df = pd.read_excel(f)\n",
    "        df.loc[df['siamese_prediction'].astype(float) < 0.9, 'kg_id'] = 'NIL'\n",
    "        df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_NIL(colorized_path, output_path):\n",
    "    file_list = glob.glob(colorized_path + '/*.xlsx')\n",
    "    for i, f in tqdm(enumerate(file_list)):\n",
    "        f_name = f.split('/')[-1]\n",
    "        print(f'{f_name}: {i+1} of {len(file_list)}')\n",
    "        output_file = f\"{output_path}/{f_name[:-5]}.csv\"\n",
    "        \n",
    "        df = pd.read_excel(f)\n",
    "        ls = df.columns\n",
    "        arr = []\n",
    "        for i in range(0, len(ls)):\n",
    "            arr.append('')\n",
    "\n",
    "        arr[0] = 0\n",
    "        arr[7] = 'NIL'\n",
    "        arr[len(arr)-1] = ''\n",
    "        df_list = df.values.tolist()\n",
    "        nil = pd.DataFrame(columns = df.columns)\n",
    "        new = pd.DataFrame(columns = df.columns)\n",
    "        done = []\n",
    "        b = []\n",
    "        for i in range (0, len(df)):\n",
    "            if df['row'][i] in done:\n",
    "                continue\n",
    "\n",
    "\n",
    "            arr[1] = df['row'][i]\n",
    "            arr[2] = df['label'][i]\n",
    "            arr[3] = df['context'][i]\n",
    "            arr[4] = df['filename'][i]\n",
    "            arr[5] = df['column-id'][i]\n",
    "            arr[6] = df['label_clean'][i]\n",
    "\n",
    "\n",
    "            nil.loc[len(nil)] = arr\n",
    "\n",
    "\n",
    "            done.append(df['row'][i])\n",
    "        nil_list = nil.values.tolist()\n",
    "        for i in range(0, len(df)):\n",
    "            new.loc[len(new)] = df_list[i]\n",
    "            if i % 5 == 4:\n",
    "                new.loc[len(new)] = (nil_list[int(i/5)])\n",
    "        for i in range(0, len(new)):\n",
    "            #print(new['siamese_prediction'][i])\n",
    "            if (new['siamese_prediction'][i] == ''):\n",
    "                new['siamese_prediction'][i] = 0\n",
    "            if (new['context_score'][i] == ''):\n",
    "                new['context_score'][i] = 0\n",
    "            new['siamese_prediction'][i] = float(new['siamese_prediction'][i])\n",
    "            new['context_score'][i] = float(new['context_score'][i])\n",
    "        select = new[(new['siamese_prediction'] > siamese_threshold) | (new['kg_id'] == 'NIL')]\n",
    "        select = select.reset_index(drop = True)\n",
    "        final = pd.DataFrame(columns = df.columns)\n",
    "        done = []\n",
    "        select_list = select.values.tolist()\n",
    "        for i in range(0, len(select)):\n",
    "            if select['row'][i] in done:\n",
    "                continue\n",
    "            final.loc[len(final)] = select_list[i]\n",
    "            done.append(select['row'][i])\n",
    "        final.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nil_path = '/data/amandeep/nih-dataset/organization/with_nils'\n",
    "!mkdir -p $nil_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_0.xlsx: 1 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_1.xlsx: 2 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:03,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_2.xlsx: 3 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:04,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_3.xlsx: 4 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:05,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_4.xlsx: 5 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:07,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_5.xlsx: 6 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:08,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_6.xlsx: 7 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:10,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_7.xlsx: 8 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:11,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_8.xlsx: 9 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:13,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_9.xlsx: 10 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:14,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_0.xlsx: 11 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:15,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_1.xlsx: 12 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:17,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_2.xlsx: 13 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:18,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_3.xlsx: 14 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:20,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_4.xlsx: 15 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:21,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_5.xlsx: 16 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:22,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_6.xlsx: 17 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:24,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_7.xlsx: 18 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:25,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_8.xlsx: 19 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [00:27,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1_9.xlsx: 20 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:28,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_0.xlsx: 21 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [00:29,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_1.xlsx: 22 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [00:31,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_2.xlsx: 23 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:32,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_3.xlsx: 24 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:33,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_4.xlsx: 25 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [00:34,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_5.xlsx: 26 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:36,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_6.xlsx: 27 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:37,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_7.xlsx: 28 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:38,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_8.xlsx: 29 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29it [00:39,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2_9.xlsx: 30 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [00:40,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_0.xlsx: 31 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [00:42,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_1.xlsx: 32 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:43,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_2.xlsx: 33 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33it [00:44,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_3.xlsx: 34 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34it [00:46,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_4.xlsx: 35 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:47,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_5.xlsx: 36 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [00:49,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_6.xlsx: 37 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "37it [00:51,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_7.xlsx: 38 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38it [00:52,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_8.xlsx: 39 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39it [00:54,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3_9.xlsx: 40 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:55,  1.38s/it]\n"
     ]
    }
   ],
   "source": [
    "add_NILS(colorized_path, nil_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_non_nils(nil_path):\n",
    "    file_list = glob.glob(nil_path + '/*.csv')\n",
    "    o = list()\n",
    "    for i, f in tqdm(enumerate(file_list)):\n",
    "        f_name = f.split('/')[-1]\n",
    "        o.append(pd.read_csv(f))\n",
    "    df = pd.concat(o)\n",
    "    print(len(df[df['column'] == 2]))\n",
    "    df = df[(df['kg_id'] != 'NIL') & (df['kg_id'] != '') & (df['column'] == 2)]\n",
    "    print(len(df))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:00, 99.01it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "618\n",
      "618\n"
     ]
    }
   ],
   "source": [
    "count_non_nils(nil_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join(nil_path):\n",
    "    file_list = glob.glob(nil_path + '/*.csv')\n",
    "    o = list()\n",
    "    for i, f in tqdm(enumerate(file_list)):\n",
    "        f_name = f.split('/')[-1]\n",
    "        o.append(pd.read_csv(f))\n",
    "    df = pd.concat(o)\n",
    "    df.to_csv('/tmp/joined.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:02, 19.99it/s]\n"
     ]
    }
   ],
   "source": [
    "join(nil_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(table_path, sep='\\t').to_csv(table_path[:-4] + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "join Time: 44.72819471359253s\n"
     ]
    }
   ],
   "source": [
    "!tl join -c siamese_prediction -f /data/amandeep/nih-dataset/organization/org_for_tl_with_qnode.csv \\\n",
    "--extra-info /tmp/joined.csv > '/data/amandeep/nih-dataset/organization/org_for_tl_with_qnode_joined.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_replace_nodes_mapping(joined_file, mapping_file):\n",
    "    df = pd.read_csv(joined_file)\n",
    "    o = []\n",
    "    for i, row in df.iterrows():\n",
    "        if row['name_kg_id'].strip() != \"\":\n",
    "            o.append({\n",
    "                'node1': row['org_node'],\n",
    "                'label': 'same_as_item',\n",
    "                'node2': row['name_kg_id'],\n",
    "                'confidence': row['name_score']\n",
    "            })\n",
    "        if row['city_kg_id'].strip() != \"\":\n",
    "            o.append({\n",
    "                'node1': row['city_node'],\n",
    "                'label': 'same_as_item',\n",
    "                'node2': row['city_kg_id'],\n",
    "                'confidence': row['city_score']\n",
    "            })\n",
    "        if row['state_kg_id'].strip() != \"\":\n",
    "            o.append({\n",
    "                'node1': row['state_node'],\n",
    "                'label': 'same_as_item',\n",
    "                'node2': row['state_kg_id'],\n",
    "                'confidence': row['state_score']\n",
    "            })\n",
    "        \n",
    "        if row['country_kg_id'].strip() != \"\":\n",
    "            o.append({\n",
    "                'node1': row['country_node'],\n",
    "                'label': 'same_as_item',\n",
    "                'node2': row['country_kg_id'],\n",
    "                'confidence': row['country_score']\n",
    "            })\n",
    "\n",
    "    oo = []\n",
    "    odf = pd.DataFrame(o)\n",
    "    odf.drop_duplicates(subset=['node1', 'node2'], inplace=True)\n",
    "    for _, gdf in odf.groupby('node1'):\n",
    "        gdf = gdf[gdf['node2'] != 'NIL']\n",
    "        if len(gdf) > 1:\n",
    "            oo.append(pd.DataFrame(gdf.head(0)))\n",
    "        else:\n",
    "            oo.append(gdf)\n",
    "    pd.concat(oo).to_csv(mapping_file, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_replace_nodes_mapping('/data/amandeep/nih-dataset/organization/org_for_tl_with_qnode_joined.csv', '/data/amandeep/nih-dataset/organization/replace_nodes_mapping.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_org_files():\n",
    "    f_p = \"/data/amandeep/nih-dataset/organization/kgtk-files-nih-V3.0\"\n",
    "    o = []\n",
    "    for f in glob.glob(f\"{f_p}/*tsv\"):\n",
    "        o.append(pd.read_csv(f, sep='\\t'))\n",
    "    df = pd.concat(o)\n",
    "    df.to_csv('/data/amandeep/nih-dataset/organization/nih-org-kgtk.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_org_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kgtk replace-nodes -i nih-org-kgtk.tsv -o nih-org-kgtk-wikidata-qnodes.tsv --mapping-file replace_nodes_mapping.tsv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tl-env",
   "language": "python",
   "name": "tl-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
