{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dade20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c90f6f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_url = 'http://ckg07:9200'\n",
    "es_index = 'wikidatadwd-augmented'\n",
    "index_url = 'http://ckg07:9200/wikidatadwd-augmented/'\n",
    "\n",
    "HOME_DIR = '/home/sriamazingram/USC/Others/ISI/data/t2dv2-example'\n",
    "\n",
    "# Input Paths\n",
    "\n",
    "# GDrive Path: https://drive.google.com/drive/folders/1ESBZCgILSRnH1-jgvqpY2dKcj19MLtlq?usp=sharing\n",
    "tables_path = f\"{HOME_DIR}/t2dv2-dev-input\"\n",
    "\n",
    "# GDrive Path: https://drive.google.com/drive/folders/1gQ15t8T1HW9j1zJfThZNyk7Wfxo0-uy5?usp=sharing\n",
    "gt_path = f'{HOME_DIR}/gt'\n",
    "\n",
    "# GDrive Path: https://drive.google.com/file/d/1fC5zyD9v5KnvGY1cY1FAAe2XvJLNdxCX/view?usp=sharing\n",
    "targets_columns = f\"{HOME_DIR}/Files1.txt\"\n",
    "\n",
    "# OUTPUT PATHS\n",
    "\n",
    "canonical_path = f'{HOME_DIR}/canonical'\n",
    "candidate_path = f'{HOME_DIR}/candidates'\n",
    "feature_path = f'{HOME_DIR}/features'\n",
    "\n",
    "temp_dir = f'{HOME_DIR}/temp'\n",
    "\n",
    "output_predictions = f'{HOME_DIR}/dev_predictions'\n",
    "predictions_top_k = f'{HOME_DIR}/dev_predictions_top_k'\n",
    "colorized_path = f'{HOME_DIR}/dev_predictions_colorized'\n",
    "metrics_path = f'{HOME_DIR}/dev_predictions_metrics'\n",
    "\n",
    "aux_field = 'graph_embedding_complex,class_count,property_count,context'\n",
    "\n",
    "prop_count = f'{HOME_DIR}/property_count' \n",
    "class_count = f'{HOME_DIR}/class_count'\n",
    "context_path = f'{HOME_DIR}/context'\n",
    "embedding_path = f'{HOME_DIR}/embedding'\n",
    "\n",
    "# MODEL PATHS\n",
    "\n",
    "#GitHub Link to models: https://github.com/usc-isi-i2/table-linker-pipelines/tree/main/table-linker-full-pipeline/models\n",
    "model_file_path = './models/weighted_lr.pkl'\n",
    "ranking_model_file_path = './models/epoch_5_loss_0.09882864356040955_top1_0.8968926553672316.pth'\n",
    "min_max_scaler_path = './models/normalization_factor.pkl'\n",
    "\n",
    "final_score_column = \"siamese_prediction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6aa1a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['pagerank','retrieval_score','monge_elkan','monge_elkan_aliases','des_cont_jaccard',\n",
    "            'jaro_winkler','levenshtein','singleton','num_char','num_tokens',\n",
    "           'lof_class_count_tf_idf_score', 'lof_property_count_tf_idf_score',\n",
    "           'lof-graph-embedding-score', 'lof-reciprocal-rank', 'context_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33269d9c",
   "metadata": {},
   "source": [
    "### Create folders for storing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf3f83dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $temp_dir\n",
    "!mkdir -p $canonical_path\n",
    "!mkdir -p $candidate_path\n",
    "!mkdir -p $feature_path\n",
    "!mkdir -p $output_predictions\n",
    "!mkdir -p $predictions_top_k\n",
    "!mkdir -p $colorized_path\n",
    "!mkdir -p $metrics_path\n",
    "!mkdir -p $prop_count\n",
    "!mkdir -p $class_count\n",
    "!mkdir -p $context_path\n",
    "!mkdir -p $embedding_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc2f06b",
   "metadata": {},
   "source": [
    "### Canonicalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fd22d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File:84575189_0_6365692015941409487 - Column:Journal\n",
      "canonicalize Time: 0.0036840438842773438s\n",
      "File:28086084_0_3127660530989916727 - Column:Saint\n",
      "canonicalize Time: 0.004144906997680664s\n",
      "File:50270082_0_444360818941411589 - Column:Player (2011 Ws)\n",
      "canonicalize Time: 0.011132478713989258s\n",
      "File:29414811_2_4773219892816395776 - Column:Game\n",
      "canonicalize Time: 0.0030183792114257812s\n",
      "File:39759273_0_1427898308030295194 - Column:Title\n",
      "canonicalize Time: 0.0033702850341796875s\n",
      "File:14380604_4_3329235705746762392 - Column:Company\n",
      "canonicalize Time: 0.0032808780670166016s\n",
      "File:1438042986423_95_20150728002306-00329-ip-10-236-191-2_805336391_10 - Column:Name\n",
      "canonicalize Time: 0.003033876419067383s\n",
      "File:14067031_0_559833072073397908 - Column:OAU State\n",
      "canonicalize Time: 0.0035049915313720703s\n",
      "File:45073662_0_3179937335063201739 - Column:Player (2011 TBs)\n",
      "canonicalize Time: 0.0027573108673095703s\n",
      "File:52299421_0_4473286348258170200 - Column:1998 Data Country\n",
      "canonicalize Time: 0.00403594970703125s\n"
     ]
    }
   ],
   "source": [
    "targets = pd.read_csv(targets_columns, header=None, index_col=0)\n",
    "for file in glob.glob(tables_path+\"/*.csv\"):\n",
    "    \n",
    "    filename = file.split(\"/\")[-1].split(\".csv\")[0]\n",
    "    column_name = targets.loc[filename][1]\n",
    "    canonical_file = f'{canonical_path}/{file.split(\"/\")[-1]}'\n",
    "    print(f\"File:{filename} - Column:{column_name}\")\n",
    "    \n",
    "    !tl canonicalize $file -c \"$column_name\" --add-context > $canonical_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ab2723",
   "metadata": {},
   "source": [
    "### Candidate Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c49ba2ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84575189_0_6365692015941409487.csv\n",
      "clean Time: 0.005683183670043945s\n",
      "get-fuzzy-augmented-matches Time: 13.465822696685791s\n",
      "get-exact-matches Time: 5.890868902206421s\n",
      "ground-truth-labeler Time: 0.22819805145263672s\n",
      "28086084_0_3127660530989916727.csv\n",
      "clean Time: 0.009492158889770508s\n",
      "get-fuzzy-augmented-matches Time: 20.001757383346558s\n",
      "get-exact-matches Time: 16.32868981361389s\n",
      "ground-truth-labeler Time: 0.40917015075683594s\n",
      "50270082_0_444360818941411589.csv\n",
      "clean Time: 0.0070629119873046875s\n",
      "get-fuzzy-augmented-matches Time: 18.000375270843506s\n",
      "get-exact-matches Time: 6.323396682739258s\n",
      "ground-truth-labeler Time: 0.2840452194213867s\n",
      "29414811_2_4773219892816395776.csv\n",
      "clean Time: 0.0017108917236328125s\n",
      "get-fuzzy-augmented-matches Time: 7.4294703006744385s\n",
      "get-exact-matches Time: 0.40150976181030273s\n",
      "ground-truth-labeler Time: 0.052536964416503906s\n",
      "39759273_0_1427898308030295194.csv\n",
      "clean Time: 0.0049190521240234375s\n",
      "get-fuzzy-augmented-matches Time: 11.664368629455566s\n",
      "get-exact-matches Time: 5.672713041305542s\n",
      "ground-truth-labeler Time: 0.1896209716796875s\n",
      "14380604_4_3329235705746762392.csv\n",
      "clean Time: 0.0014989376068115234s\n",
      "get-fuzzy-augmented-matches Time: 7.042949914932251s\n",
      "get-exact-matches Time: 0.38936305046081543s\n",
      "ground-truth-labeler Time: 0.053639888763427734s\n",
      "1438042986423_95_20150728002306-00329-ip-10-236-191-2_805336391_10.csv\n",
      "clean Time: 0.001176595687866211s\n",
      "get-fuzzy-augmented-matches Time: 6.716838836669922s\n",
      "get-exact-matches Time: 0.45183467864990234s\n",
      "ground-truth-labeler Time: 0.03072500228881836s\n",
      "14067031_0_559833072073397908.csv\n",
      "clean Time: 0.004853248596191406s\n",
      "get-fuzzy-augmented-matches Time: 10.748355150222778s\n",
      "get-exact-matches Time: 5.425442457199097s\n",
      "ground-truth-labeler Time: 0.13092350959777832s\n",
      "45073662_0_3179937335063201739.csv\n",
      "clean Time: 0.0017604827880859375s\n",
      "get-fuzzy-augmented-matches Time: 12.493775129318237s\n",
      "get-exact-matches Time: 0.4067513942718506s\n",
      "ground-truth-labeler Time: 0.0650947093963623s\n",
      "52299421_0_4473286348258170200.csv\n",
      "clean Time: 0.004178285598754883s\n",
      "get-fuzzy-augmented-matches Time: 14.049508094787598s\n",
      "get-exact-matches Time: 5.8690972328186035s\n",
      "ground-truth-labeler Time: 0.2630326747894287s\n"
     ]
    }
   ],
   "source": [
    "for file in glob.glob(canonical_path+\"/*.csv\"):\n",
    "    \n",
    "    filename = file.split(\"/\")[-1]\n",
    "    candidate_file_path = f'{candidate_path}/{filename}'\n",
    "    gt_file = f'{gt_path}/{filename}'\n",
    "    \n",
    "    print(filename)\n",
    "    \n",
    "    !tl clean -c label -o label_clean \"$file\" \\\n",
    "    / --url \"$es_url\" --index \"$es_index\" \\\n",
    "    get-fuzzy-augmented-matches -c label_clean \\\n",
    "    --auxiliary-fields \"$aux_field\" \\\n",
    "    --auxiliary-folder \"$temp_dir\" \\\n",
    "    / --url \"$es_url\" --index \"$es_index\" \\\n",
    "    get-exact-matches \\\n",
    "    -c label_clean --auxiliary-fields \"$aux_field\" \\\n",
    "    --auxiliary-folder \"$temp_dir\" \\\n",
    "    / ground-truth-labeler --gt-file $gt_file > \"$candidate_file_path\"\n",
    "    \n",
    "    for field in aux_field.split(','):\n",
    "        aux_list = []\n",
    "        for f in glob.glob(f'{temp_dir}/*{field}.tsv'):\n",
    "            aux_list.append(pd.read_csv(f, sep='\\t', dtype=object))\n",
    "        aux_df = pd.concat(aux_list).drop_duplicates(subset=['qnode'])\n",
    "        if field == 'class_count':\n",
    "            class_count_file = f\"{class_count}/{filename.strip('.csv')}_class_count.tsv\"\n",
    "            aux_df.to_csv(class_count_file, sep='\\t', index=False)\n",
    "        elif field == 'property_count':\n",
    "            prop_count_file = f\"{prop_count}/{filename.strip('.csv')}_prop_count.tsv\"\n",
    "            aux_df.to_csv(prop_count_file, sep='\\t', index=False)\n",
    "        elif field == 'context':\n",
    "            context_file = f\"{context_path}/{filename.strip('.csv')}_context.tsv\"\n",
    "            aux_df.to_csv(context_file, sep='\\t', index=False)\n",
    "        elif field == 'graph_embedding_complex':\n",
    "            embedding_file = f\"{embedding_path}/{filename.strip('.csv')}_embedding.tsv\"\n",
    "            aux_df.to_csv(embedding_file, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328985b2",
   "metadata": {},
   "source": [
    "### Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d0420b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84575189_0_6365692015941409487.csv\n",
      "align-page-rank Time: 0.678173303604126s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 5.831399440765381s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 11.020357370376587s\n",
      "string-similarity-['jaro_winkler'] Time: 0.9630706310272217s\n",
      "string-similarity-['levenshtein'] Time: 7.7811009883880615s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 0.10764527320861816s\n",
      "normalize-scores-des_cont_jaccard Time: 0.04472160339355469s\n",
      "smallest-qnode-number Time: 0.4096338748931885s\n",
      "mosaic-features Time: 0.01918482780456543s\n",
      "create-singleton-feature Time: 0.2456960678100586s\n",
      "/home/sriamazingram/USC/Others/ISI/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.3747282028198242s\n",
      "Qnodes to lookup: 8831\n",
      "Qnodes from file: 8346\n",
      "Qnodes from server: 0\n",
      "Outlier removal generates 47 lof-voted candidates\n",
      "score-using-embedding Time: 34.37578725814819s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.16823887825012207s\n",
      "compute-tf-idf-class_count Time: 36.167837619781494s\n",
      "compute-tf-idf-property_count Time: 36.88792014122009s\n",
      "context-match Time: 23.785550594329834s\n",
      "28086084_0_3127660530989916727.csv\n",
      "align-page-rank Time: 1.6237759590148926s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 9.457733154296875s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 32.7160382270813s\n",
      "string-similarity-['jaro_winkler'] Time: 2.1081225872039795s\n",
      "string-similarity-['levenshtein'] Time: 10.103736400604248s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 0.5133302211761475s\n",
      "normalize-scores-des_cont_jaccard Time: 0.10325050354003906s\n",
      "smallest-qnode-number Time: 0.9265692234039307s\n",
      "mosaic-features Time: 0.045804738998413086s\n",
      "create-singleton-feature Time: 0.593641996383667s\n",
      "/home/sriamazingram/USC/Others/ISI/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.37354373931884766s\n",
      "Qnodes to lookup: 21253\n",
      "Qnodes from file: 20951\n",
      "Qnodes from server: 0\n",
      "Outlier removal generates 91 lof-voted candidates\n",
      "score-using-embedding Time: 69.81355547904968s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.324143648147583s\n",
      "compute-tf-idf-class_count Time: 72.96475458145142s\n",
      "compute-tf-idf-property_count Time: 74.09155941009521s\n",
      "context-match Time: 135.7475287914276s\n",
      "50270082_0_444360818941411589.csv\n",
      "align-page-rank Time: 1.2835211753845215s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 2.740922689437866s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 8.486894130706787s\n",
      "string-similarity-['jaro_winkler'] Time: 0.7604737281799316s\n",
      "string-similarity-['levenshtein'] Time: 2.9780333042144775s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 0.17800664901733398s\n",
      "normalize-scores-des_cont_jaccard Time: 0.07857203483581543s\n",
      "smallest-qnode-number Time: 0.7179336547851562s\n",
      "mosaic-features Time: 0.02927851676940918s\n",
      "create-singleton-feature Time: 0.4397432804107666s\n",
      "/home/sriamazingram/USC/Others/ISI/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.37961649894714355s\n",
      "Qnodes to lookup: 17733\n",
      "Qnodes from file: 17622\n",
      "Qnodes from server: 0\n",
      "_centroid_of_lof: Missing 31 of 894\n",
      "Outlier removal generates 518 lof-voted candidates\n",
      "score-using-embedding Time: 26.236613512039185s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.2500419616699219s\n",
      "compute-tf-idf-class_count Time: 28.456284761428833s\n",
      "compute-tf-idf-property_count Time: 29.501420259475708s\n",
      "context-match Time: 56.93658781051636s\n",
      "29414811_2_4773219892816395776.csv\n",
      "align-page-rank Time: 0.21879863739013672s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 1.1686275005340576s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 3.1502346992492676s\n",
      "string-similarity-['jaro_winkler'] Time: 0.17547345161437988s\n",
      "string-similarity-['levenshtein'] Time: 1.0887513160705566s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 0.044129371643066406s\n",
      "normalize-scores-des_cont_jaccard Time: 0.017356395721435547s\n",
      "smallest-qnode-number Time: 0.09793257713317871s\n",
      "mosaic-features Time: 0.006112813949584961s\n",
      "create-singleton-feature Time: 0.06103205680847168s\n",
      "/home/sriamazingram/USC/Others/ISI/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.33588290214538574s\n",
      "Qnodes to lookup: 2222\n",
      "Qnodes from file: 2137\n",
      "Qnodes from server: 0\n",
      "Outlier removal generates 24 lof-voted candidates\n",
      "score-using-embedding Time: 11.028916120529175s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.04346060752868652s\n",
      "compute-tf-idf-class_count Time: 11.965080976486206s\n",
      "compute-tf-idf-property_count Time: 11.8635835647583s\n",
      "context-match Time: 27.2659854888916s\n",
      "39759273_0_1427898308030295194.csv\n",
      "align-page-rank Time: 0.672722578048706s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 5.284438371658325s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 13.360914468765259s\n",
      "string-similarity-['jaro_winkler'] Time: 0.8760972023010254s\n",
      "string-similarity-['levenshtein'] Time: 5.553746700286865s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 0.227522611618042s\n",
      "normalize-scores-des_cont_jaccard Time: 0.04990553855895996s\n",
      "smallest-qnode-number Time: 0.4110903739929199s\n",
      "mosaic-features Time: 0.021669864654541016s\n",
      "create-singleton-feature Time: 0.26801228523254395s\n",
      "/home/sriamazingram/USC/Others/ISI/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.3444807529449463s\n",
      "Qnodes to lookup: 10916\n",
      "Qnodes from file: 10587\n",
      "Qnodes from server: 0\n",
      "Outlier removal generates 109 lof-voted candidates\n",
      "score-using-embedding Time: 34.02807545661926s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.1528480052947998s\n",
      "compute-tf-idf-class_count Time: 35.71675133705139s\n",
      "compute-tf-idf-property_count Time: 36.53131413459778s\n",
      "context-match Time: 64.48705530166626s\n",
      "14380604_4_3329235705746762392.csv\n",
      "align-page-rank Time: 0.2771155834197998s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 0.6053032875061035s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 0.9957170486450195s\n",
      "string-similarity-['jaro_winkler'] Time: 0.14766955375671387s\n",
      "string-similarity-['levenshtein'] Time: 0.6902520656585693s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 0.06768369674682617s\n",
      "normalize-scores-des_cont_jaccard Time: 0.0167539119720459s\n",
      "smallest-qnode-number Time: 0.08894109725952148s\n",
      "mosaic-features Time: 0.006247520446777344s\n",
      "create-singleton-feature Time: 0.06928300857543945s\n",
      "/home/sriamazingram/USC/Others/ISI/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.3342142105102539s\n",
      "Qnodes to lookup: 2520\n",
      "Qnodes from file: 2451\n",
      "Qnodes from server: 0\n",
      "Outlier removal generates 8 lof-voted candidates\n",
      "score-using-embedding Time: 7.721702814102173s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.041112661361694336s\n",
      "compute-tf-idf-class_count Time: 8.327234506607056s\n",
      "compute-tf-idf-property_count Time: 8.741161346435547s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context-match Time: 14.177937507629395s\n",
      "14067031_0_559833072073397908.csv\n",
      "align-page-rank Time: 0.32572340965270996s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 3.1700901985168457s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 3.6154298782348633s\n",
      "string-similarity-['jaro_winkler'] Time: 0.7208642959594727s\n",
      "string-similarity-['levenshtein'] Time: 3.8121352195739746s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 0.20200133323669434s\n",
      "normalize-scores-des_cont_jaccard Time: 0.035929203033447266s\n",
      "smallest-qnode-number Time: 0.2347867488861084s\n",
      "mosaic-features Time: 0.01794910430908203s\n",
      "create-singleton-feature Time: 0.18232131004333496s\n",
      "/home/sriamazingram/USC/Others/ISI/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.33574342727661133s\n",
      "Qnodes to lookup: 7862\n",
      "Qnodes from file: 7606\n",
      "Qnodes from server: 0\n",
      "Outlier removal generates 59 lof-voted candidates\n",
      "score-using-embedding Time: 19.20608615875244s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.09061288833618164s\n",
      "compute-tf-idf-class_count Time: 20.552590131759644s\n",
      "compute-tf-idf-property_count Time: 21.04085683822632s\n",
      "context-match Time: 83.32798027992249s\n",
      "45073662_0_3179937335063201739.csv\n",
      "align-page-rank Time: 0.3751242160797119s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 0.5827674865722656s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 1.5917787551879883s\n",
      "string-similarity-['jaro_winkler'] Time: 0.14527010917663574s\n",
      "string-similarity-['levenshtein'] Time: 0.5322229862213135s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 0.03548789024353027s\n",
      "normalize-scores-des_cont_jaccard Time: 0.018566131591796875s\n",
      "smallest-qnode-number Time: 0.11586976051330566s\n",
      "mosaic-features Time: 0.006436824798583984s\n",
      "create-singleton-feature Time: 0.0801692008972168s\n",
      "/home/sriamazingram/USC/Others/ISI/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.3376426696777344s\n",
      "Qnodes to lookup: 3262\n",
      "Qnodes from file: 3234\n",
      "Qnodes from server: 0\n",
      "Outlier removal generates 9 lof-voted candidates\n",
      "score-using-embedding Time: 8.237966299057007s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.052557945251464844s\n",
      "compute-tf-idf-class_count Time: 8.995386600494385s\n",
      "compute-tf-idf-property_count Time: 9.3403902053833s\n",
      "context-match Time: 5.261245965957642s\n",
      "52299421_0_4473286348258170200.csv\n",
      "align-page-rank Time: 0.5881960391998291s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 5.70996356010437s\n",
      "string-similarity-['symmetric_monge_elkan:tokenizer=word'] Time: 8.732712507247925s\n",
      "string-similarity-['jaro_winkler'] Time: 1.3965976238250732s\n",
      "string-similarity-['levenshtein'] Time: 6.7874133586883545s\n",
      "string-similarity-['jaccard:tokenizer=word'] Time: 0.45211172103881836s\n",
      "normalize-scores-des_cont_jaccard Time: 0.07017087936401367s\n",
      "smallest-qnode-number Time: 0.4086487293243408s\n",
      "mosaic-features Time: 0.03379464149475098s\n",
      "create-singleton-feature Time: 0.36559605598449707s\n",
      "/home/sriamazingram/USC/Others/ISI/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "vote-by-classifier Time: 0.3571195602416992s\n",
      "Qnodes to lookup: 15624\n",
      "Qnodes from file: 15286\n",
      "Qnodes from server: 0\n",
      "Outlier removal generates 92 lof-voted candidates\n",
      "score-using-embedding Time: 34.19866585731506s\n",
      "generate-reciprocal-rank-lof-graph-embedding-score Time: 0.15593552589416504s\n",
      "compute-tf-idf-class_count Time: 36.18795466423035s\n",
      "compute-tf-idf-property_count Time: 37.33047080039978s\n",
      "context-match Time: 144.72061491012573s\n"
     ]
    }
   ],
   "source": [
    "for file in glob.glob(candidate_path+\"/*.csv\"):\n",
    "    \n",
    "    filename = file.split(\"/\")[-1]\n",
    "    feature_file = f'{feature_path}/{filename}'\n",
    "    context_file = f'{context_path}/{filename.strip(\".csv\")}_context.tsv'\n",
    "    graph_embedding_complex_file = f'{embedding_path}/{filename.strip(\".csv\")}_embedding.tsv'\n",
    "    class_count_file = f'{class_count}/{filename.strip(\".csv\")}_class_count.tsv'\n",
    "    property_count_file = f'{prop_count}/{filename.strip(\".csv\")}_prop_count.tsv'\n",
    "    \n",
    "    if filename == \"1438042986423_95_20150728002306-00329-ip-10-236-191-2_805336391_10.csv\":\n",
    "        continue\n",
    "    print(filename)\n",
    "    # Aligned page rank\n",
    "    # String similarity features\n",
    "    # Normalize Jaccard similarity\n",
    "    # Calculate mosaic features\n",
    "    # Singleton feature\n",
    "    # Most voted candidates result\n",
    "    # Graph-embedding-score using centroid-of-lof and lof-strategy\n",
    "    # LOF reciprocal rank feature\n",
    "    # LOF TF-IDF feature for classes and properties\n",
    "    # Context Match feature\n",
    "    \n",
    "    !tl align-page-rank $file \\\n",
    "    / string-similarity -i --method symmetric_monge_elkan:tokenizer=word -o monge_elkan \\\n",
    "    / string-similarity -i --method symmetric_monge_elkan:tokenizer=word -c label_clean kg_aliases -o monge_elkan_aliases \\\n",
    "    / string-similarity -i --method jaro_winkler -o jaro_winkler \\\n",
    "    / string-similarity -i --method levenshtein -o levenshtein \\\n",
    "    / string-similarity -i --method jaccard:tokenizer=word -c kg_descriptions context -o des_cont_jaccard \\\n",
    "    / normalize-scores -c des_cont_jaccard / smallest-qnode-number \\\n",
    "    / mosaic-features -c kg_labels --num-char --num-tokens \\\n",
    "    / create-singleton-feature -o singleton \\\n",
    "    / vote-by-classifier \\\n",
    "    --prob-threshold 0.995 \\\n",
    "    --model $model_file_path \\\n",
    "    --features \"aligned_pagerank,smallest_qnode_number,monge_elkan,des_cont_jaccard_normalized\" \\\n",
    "    / score-using-embedding \\\n",
    "    --column-vector-strategy centroid-of-lof \\\n",
    "    --lof-strategy ems-mv \\\n",
    "    -o lof-graph-embedding-score \\\n",
    "    --embedding-file $graph_embedding_complex_file \\\n",
    "    --embedding-url $index_url \\\n",
    "    / generate-reciprocal-rank \\\n",
    "    -c lof-graph-embedding-score \\\n",
    "    -o lof-reciprocal-rank \\\n",
    "    / compute-tf-idf \\\n",
    "    --feature-file \"$class_count_file\" \\\n",
    "    --feature-name class_count \\\n",
    "    --singleton-column is_lof \\\n",
    "    -o lof_class_count_tf_idf_score \\\n",
    "    / compute-tf-idf \\\n",
    "    --feature-file \"$property_count_file\" \\\n",
    "    --feature-name property_count \\\n",
    "    --singleton-column is_lof \\\n",
    "    -o lof_property_count_tf_idf_score \\\n",
    "    / context-match \\\n",
    "    --context-file $context_file  \\\n",
    "    -o context_score \\\n",
    "    --debug \\\n",
    "    > \"$feature_file\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fc66a7",
   "metadata": {},
   "source": [
    "### Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a091935",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84575189_0_6365692015941409487.csv\n",
      "/home/sriamazingram/USC/Others/ISI/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 1.0456326007843018s\n",
      "28086084_0_3127660530989916727.csv\n",
      "/home/sriamazingram/USC/Others/ISI/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 1.9411087036132812s\n",
      "50270082_0_444360818941411589.csv\n",
      "/home/sriamazingram/USC/Others/ISI/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 1.5260703563690186s\n",
      "29414811_2_4773219892816395776.csv\n",
      "/home/sriamazingram/USC/Others/ISI/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 0.497922420501709s\n",
      "39759273_0_1427898308030295194.csv\n",
      "/home/sriamazingram/USC/Others/ISI/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 1.059385061264038s\n",
      "14380604_4_3329235705746762392.csv\n",
      "/home/sriamazingram/USC/Others/ISI/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 0.4615159034729004s\n",
      "14067031_0_559833072073397908.csv\n",
      "/home/sriamazingram/USC/Others/ISI/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 0.7286100387573242s\n",
      "45073662_0_3179937335063201739.csv\n",
      "/home/sriamazingram/USC/Others/ISI/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 0.5150220394134521s\n",
      "52299421_0_4473286348258170200.csv\n",
      "/home/sriamazingram/USC/Others/ISI/tl_env/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "predict-using-model Time: 1.069216012954712s\n"
     ]
    }
   ],
   "source": [
    "features_str = \",\".join(features)\n",
    "for file in glob.glob(feature_path+\"/*.csv\"):\n",
    "    filename = file.split(\"/\")[-1]\n",
    "    \n",
    "    print(filename)\n",
    "    \n",
    "    prediction_file = f'{output_predictions}/{filename}'\n",
    "    \n",
    "    features_str = \",\".join(features)\n",
    "    !tl predict-using-model -o siamese_prediction \\\n",
    "    --ranking-model $ranking_model_file_path \\\n",
    "    --features $features_str \\\n",
    "    --normalization-factor $min_max_scaler_path $file > $prediction_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184f2056",
   "metadata": {},
   "source": [
    "### Get Top 5 Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfb86789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84575189_0_6365692015941409487.csv\n",
      "get-kg-links-siamese_prediction Time: 0.7082772254943848s\n",
      "28086084_0_3127660530989916727.csv\n",
      "get-kg-links-siamese_prediction Time: 1.5682003498077393s\n",
      "50270082_0_444360818941411589.csv\n",
      "get-kg-links-siamese_prediction Time: 1.1901907920837402s\n",
      "29414811_2_4773219892816395776.csv\n",
      "get-kg-links-siamese_prediction Time: 0.16732096672058105s\n",
      "39759273_0_1427898308030295194.csv\n",
      "get-kg-links-siamese_prediction Time: 0.7116034030914307s\n",
      "14380604_4_3329235705746762392.csv\n",
      "get-kg-links-siamese_prediction Time: 0.1615145206451416s\n",
      "14067031_0_559833072073397908.csv\n",
      "get-kg-links-siamese_prediction Time: 0.4001154899597168s\n",
      "45073662_0_3179937335063201739.csv\n",
      "get-kg-links-siamese_prediction Time: 0.20262742042541504s\n",
      "52299421_0_4473286348258170200.csv\n",
      "get-kg-links-siamese_prediction Time: 0.6912147998809814s\n"
     ]
    }
   ],
   "source": [
    "for file in glob.glob(output_predictions+\"/*.csv\"):\n",
    "    filename = file.split(\"/\")[-1]\n",
    "    \n",
    "    print(filename)\n",
    "    \n",
    "    top_k_file = f'{predictions_top_k}/{filename}'\n",
    "    \n",
    "    !tl get-kg-links -c $final_score_column -k 5 --k-rows $file > $top_k_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6b096d",
   "metadata": {},
   "source": [
    "### Colorize the predicted files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48127a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84575189_0_6365692015941409487.csv\n",
      "add-color Time: 0.15748333930969238s\n",
      "28086084_0_3127660530989916727.csv\n",
      "add-color Time: 0.3238708972930908s\n",
      "50270082_0_444360818941411589.csv\n",
      "add-color Time: 0.23525667190551758s\n",
      "29414811_2_4773219892816395776.csv\n",
      "add-color Time: 0.06061553955078125s\n",
      "39759273_0_1427898308030295194.csv\n",
      "add-color Time: 0.1501917839050293s\n",
      "14380604_4_3329235705746762392.csv\n",
      "add-color Time: 0.05891609191894531s\n",
      "14067031_0_559833072073397908.csv\n",
      "add-color Time: 0.09913015365600586s\n",
      "45073662_0_3179937335063201739.csv\n",
      "add-color Time: 0.06687641143798828s\n",
      "52299421_0_4473286348258170200.csv\n",
      "add-color Time: 0.13943266868591309s\n"
     ]
    }
   ],
   "source": [
    "for file in glob.glob(predictions_top_k+\"/*.csv\"):\n",
    "    filename = file.split(\"/\")[-1]\n",
    "    \n",
    "    print(filename)\n",
    "    \n",
    "    colorized = f'{colorized_path}/{filename.strip(\".csv\")}.xlsx'\n",
    "    \n",
    "    !tl add-color -c \"$final_score_column,evaluation_label\" -k 5 $file --output \"$colorized\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696d9710",
   "metadata": {},
   "source": [
    "### Measure the metrics for the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d53a1f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84575189_0_6365692015941409487.csv\n",
      "metrics Time: 0.5001442432403564s\n",
      "28086084_0_3127660530989916727.csv\n",
      "metrics Time: 0.9671831130981445s\n",
      "50270082_0_444360818941411589.csv\n",
      "metrics Time: 0.7799386978149414s\n",
      "29414811_2_4773219892816395776.csv\n",
      "metrics Time: 0.14821624755859375s\n",
      "39759273_0_1427898308030295194.csv\n",
      "metrics Time: 0.4858057498931885s\n",
      "14380604_4_3329235705746762392.csv\n",
      "metrics Time: 0.1184241771697998s\n",
      "14067031_0_559833072073397908.csv\n",
      "metrics Time: 0.29844236373901367s\n",
      "45073662_0_3179937335063201739.csv\n",
      "metrics Time: 0.15725111961364746s\n",
      "52299421_0_4473286348258170200.csv\n",
      "metrics Time: 0.4804060459136963s\n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "for file in glob.glob(predictions_top_k+\"/*.csv\"):\n",
    "    filename = file.split(\"/\")[-1]\n",
    "    \n",
    "    print(filename)\n",
    "    \n",
    "    metrics_file = f'{metrics_path}/{filename}'\n",
    "    \n",
    "    !tl metrics $file -k 5 -c $final_score_column --tag $filename> $metrics_file\n",
    "    \n",
    "    df_list.append(pd.read_csv(metrics_file))\n",
    "    \n",
    "metrics_df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21a2e5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.942526</td>\n",
       "      <td>0.908163</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>84575189_0_6365692015941409487.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.841411</td>\n",
       "      <td>0.804545</td>\n",
       "      <td>0.881818</td>\n",
       "      <td>28086084_0_3127660530989916727.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.959752</td>\n",
       "      <td>0.922619</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50270082_0_444360818941411589.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29414811_2_4773219892816395776.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>39759273_0_1427898308030295194.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14380604_4_3329235705746762392.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>14067031_0_559833072073397908.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>45073662_0_3179937335063201739.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.978022</td>\n",
       "      <td>0.978022</td>\n",
       "      <td>0.978022</td>\n",
       "      <td>52299421_0_4473286348258170200.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k        f1  precision    recall                                 tag\n",
       "0  5  0.942526   0.908163  0.979592  84575189_0_6365692015941409487.csv\n",
       "0  5  0.841411   0.804545  0.881818  28086084_0_3127660530989916727.csv\n",
       "0  5  0.959752   0.922619  1.000000   50270082_0_444360818941411589.csv\n",
       "0  5  0.926829   0.863636  1.000000  29414811_2_4773219892816395776.csv\n",
       "0  5  0.990000   0.990000  0.990000  39759273_0_1427898308030295194.csv\n",
       "0  5  1.000000   1.000000  1.000000  14380604_4_3329235705746762392.csv\n",
       "0  5  0.981132   0.981132  0.981132   14067031_0_559833072073397908.csv\n",
       "0  5  0.981132   0.962963  1.000000  45073662_0_3179937335063201739.csv\n",
       "0  5  0.978022   0.978022  0.978022  52299421_0_4473286348258170200.csv"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c1b4acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.to_csv(metrics_path+\"/metrics_top_5.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tl_env",
   "language": "python",
   "name": "tl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
