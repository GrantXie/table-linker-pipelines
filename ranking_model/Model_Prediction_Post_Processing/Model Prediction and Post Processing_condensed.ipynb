{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ef7a655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "import glob\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "362d0839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paths to the required files.\n",
    "\n",
    "#dev_path: path where data files to be tested are stored.\n",
    "#G:Drive Link - https://drive.google.com/drive/u/1/folders/13OtEj6WDIng-XfQTqjC3hkrFbavPWQfa\n",
    "dev_path = \"./dev_with_lof_context/\"\n",
    "\n",
    "#dev_predictions: path where the results of predictions for each data file will be present\n",
    "dev_predictions = './dev_predictions/'\n",
    "\n",
    "#temp: temporary files are stored here.\n",
    "temp = \"./temp/\"\n",
    "#temporary storing for top 5 candidates.\n",
    "temp_predicted_top_5 = \"./temp/predicted_top_5/\"\n",
    "#temporary storing the files with ranks\n",
    "temp_predicted_ranks = \"./temp/predicted_ranks/\"\n",
    "\n",
    "#Colored XLSX Files with top 5 candidates\n",
    "dev_predictions_colored = './dev_predictions_colored/'\n",
    "\n",
    "#correct_vs_incorrect: path where the top 1 correct vs top 1 predicted for each wrong prediction is present.\n",
    "correct_vs_incorrect = \"./correct_vs_incorrect.xlsx\"\n",
    "\n",
    "#dev_output_results: The final results where rank and correct column will be present as well. \n",
    "dev_output_results = './dev_output_results/'\n",
    "#Location where the saved models and normalization factor is present.\n",
    "saved_model = \"./saved_models/epoch_4_loss_0.0869859904050827_top1_0.9081920903954802.pth\"\n",
    "normalization_file_path = './saved_models/normalization_factor.pkl'\n",
    "\n",
    "#Column name for predictions\n",
    "output_col = 'siamese_pred'\n",
    "\n",
    "!mkdir -p {dev_predictions}\n",
    "!mkdir -p {temp}\n",
    "!mkdir -p {dev_predictions_colored}\n",
    "!mkdir -p {dev_output_results}\n",
    "!mkdir -p {temp_predicted_top_5}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c755be54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace with metrics command\n",
    "def parse_eval_files_stats(eval_data, method):\n",
    "    #print(eval_data.head(5))\n",
    "    #print(method)\n",
    "    res = {}\n",
    "    candidate_eval_data = eval_data.groupby(['table_id', 'row', 'column'])['table_id'].count().reset_index(name=\"count\")\n",
    "    res['num_tasks'] = len(eval_data.groupby(['table_id', 'row', 'column']))\n",
    "    res['num_tasks_with_gt'] = len(eval_data[pd.notna(eval_data['GT_kg_id'])].groupby(['table_id', 'row', 'column']))\n",
    "    res['num_tasks_with_gt_in_candidate'] = len(eval_data[eval_data['evaluation_label'] == 1].groupby(['table_id', 'row', 'column']))\n",
    "    res['num_tasks_with_singleton_candidate'] = len(candidate_eval_data[candidate_eval_data['count'] == 1].groupby(['table_id', 'row', 'column']))\n",
    "    singleton_eval_data = candidate_eval_data[candidate_eval_data['count'] == 1]\n",
    "    num_tasks_with_singleton_candidate_with_gt = 0\n",
    "    for i, row in singleton_eval_data.iterrows():\n",
    "        table_id, row_idx, col_idx = row['table_id'], row['row'], row['column']\n",
    "        c_e_data = eval_data[(eval_data['table_id'] == table_id) & (eval_data['row'] == row_idx) & (eval_data['column'] == col_idx)]\n",
    "        assert len(c_e_data) == 1\n",
    "        if c_e_data.iloc[0]['evaluation_label'] == 1:\n",
    "            num_tasks_with_singleton_candidate_with_gt += 1\n",
    "    res['num_tasks_with_singleton_candidate_with_gt'] = num_tasks_with_singleton_candidate_with_gt\n",
    "    num_tasks_with_graph_top_one_accurate = []\n",
    "    num_tasks_with_graph_top_five_accurate = []\n",
    "    num_tasks_with_graph_top_ten_accurate = []\n",
    "    num_tasks_with_model_score_top_one_accurate = []\n",
    "    num_tasks_with_model_score_top_five_accurate = []\n",
    "    num_tasks_with_model_score_top_ten_accurate = []\n",
    "    has_gt_list = []\n",
    "    has_gt_in_candidate = []\n",
    "    # candidate_eval_data = candidate_eval_data[:1]\n",
    "    for i, row in candidate_eval_data.iterrows():\n",
    "        #print(i)\n",
    "        table_id, row_idx, col_idx = row['table_id'], row['row'], row['column']\n",
    "        c_e_data = eval_data[(eval_data['table_id'] == table_id) & (eval_data['row'] == row_idx) & (eval_data['column'] == col_idx)]\n",
    "        assert len(c_e_data) > 0\n",
    "        if np.nan not in set(c_e_data['GT_kg_id']):\n",
    "            has_gt_list.append(1)\n",
    "        else:\n",
    "            has_gt_list.append(0)\n",
    "        if 1 in set(c_e_data['evaluation_label']):\n",
    "            has_gt_in_candidate.append(1)\n",
    "        else:\n",
    "            has_gt_in_candidate.append(0)\n",
    "            \n",
    "        # handle graph-embedding-score\n",
    "        s_data = c_e_data.sort_values(by=['lof-graph-embedding-score'], ascending=False)\n",
    "        if s_data.iloc[0]['evaluation_label'] == 1:\n",
    "            num_tasks_with_graph_top_one_accurate.append(1)\n",
    "        else:\n",
    "            num_tasks_with_graph_top_one_accurate.append(0)\n",
    "        if 1 in set(s_data.iloc[0:5]['evaluation_label']):\n",
    "            num_tasks_with_graph_top_five_accurate.append(1)\n",
    "        else:\n",
    "            num_tasks_with_graph_top_five_accurate.append(0)\n",
    "        if 1 in set(s_data.iloc[0:10]['evaluation_label']):\n",
    "            num_tasks_with_graph_top_ten_accurate.append(1)\n",
    "        else:\n",
    "            num_tasks_with_graph_top_ten_accurate.append(0)\n",
    "        \n",
    "        #rank on model score\n",
    "        s_data = c_e_data.sort_values(by=[method], ascending=False)\n",
    "        #print(s_data.iloc[0]['evaluation_label'])\n",
    "        if s_data.iloc[0]['evaluation_label'] == '1':\n",
    "            num_tasks_with_model_score_top_one_accurate.append(1)\n",
    "        else:\n",
    "            num_tasks_with_model_score_top_one_accurate.append(0)\n",
    "        if 1 in set(s_data.iloc[0:5]['evaluation_label']):\n",
    "            num_tasks_with_model_score_top_five_accurate.append(1)\n",
    "        else:\n",
    "            num_tasks_with_model_score_top_five_accurate.append(0)\n",
    "        if 1 in set(s_data.iloc[0:10]['evaluation_label']):\n",
    "            num_tasks_with_model_score_top_ten_accurate.append(1)\n",
    "        else:\n",
    "            num_tasks_with_model_score_top_ten_accurate.append(0)\n",
    "            \n",
    "        cf_e_data = c_e_data.copy()\n",
    "        cf_e_data['lof-graph-embedding-score'] = cf_e_data['lof-graph-embedding-score'].replace(np.nan, 0)\n",
    "        cf_e_data[method] = cf_e_data[method].replace(np.nan, 0)\n",
    "\n",
    "    candidate_eval_data['lof-graph_top_one_accurate'] = num_tasks_with_graph_top_one_accurate\n",
    "    candidate_eval_data['lof-graph_top_five_accurate'] = num_tasks_with_graph_top_five_accurate\n",
    "    candidate_eval_data['lof-graph_top_ten_accurate'] = num_tasks_with_graph_top_five_accurate\n",
    "    candidate_eval_data['model_top_one_accurate'] = num_tasks_with_model_score_top_one_accurate\n",
    "    candidate_eval_data['model_top_five_accurate'] = num_tasks_with_model_score_top_five_accurate\n",
    "    candidate_eval_data['model_top_ten_accurate'] = num_tasks_with_model_score_top_ten_accurate\n",
    "    candidate_eval_data['has_gt'] = has_gt_list\n",
    "    candidate_eval_data['has_gt_in_candidate'] = has_gt_in_candidate\n",
    "    res['num_tasks_with_graph_top_one_accurate'] = sum(num_tasks_with_graph_top_one_accurate)\n",
    "    res['num_tasks_with_graph_top_five_accurate'] = sum(num_tasks_with_graph_top_five_accurate)\n",
    "    res['num_tasks_with_graph_top_ten_accurate'] = sum(num_tasks_with_graph_top_ten_accurate)\n",
    "    res['num_tasks_with_model_score_top_one_accurate'] = sum(num_tasks_with_model_score_top_one_accurate)\n",
    "    res['num_tasks_with_model_score_top_five_accurate'] = sum(num_tasks_with_model_score_top_five_accurate)\n",
    "    res['num_tasks_with_model_score_top_ten_accurate'] = sum(num_tasks_with_model_score_top_ten_accurate)\n",
    "    return res, candidate_eval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a273f829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "class PairwiseNetwork(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        #original 12x24, 24x12, 12x12, 12x1\n",
    "        self.fc1 = nn.Linear(hidden_size, 2*hidden_size)\n",
    "        self.fc2 = nn.Linear(2*hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, pos_features, neg_features):\n",
    "        # Positive pass\n",
    "        x = F.relu(self.fc1(pos_features))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        pos_out = torch.sigmoid(self.fc4(x))\n",
    "        \n",
    "        # Negative Pass\n",
    "        x = F.relu(self.fc1(neg_features))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        neg_out = torch.sigmoid(self.fc4(x))\n",
    "        \n",
    "        return pos_out, neg_out\n",
    "    \n",
    "    def predict(self, test_feat):\n",
    "        x = F.relu(self.fc1(test_feat))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        test_out = torch.sigmoid(self.fc4(x))\n",
    "        return test_out\n",
    "\n",
    "\n",
    "def predict(output_column, ranking_model, min_max_scaler_path, file_path=None, df=None):\n",
    "    if file_path is None and df is None:\n",
    "        raise RequiredInputParameterMissingException(\n",
    "            'One of the input parameters is required: {} or {}'.format(\"file_path\", \"df\"))\n",
    "\n",
    "    if file_path:\n",
    "        df = pd.read_csv(file_path, dtype=object)\n",
    "\n",
    "    model = PairwiseNetwork(14)\n",
    "    model.load_state_dict(torch.load(ranking_model))\n",
    "    scaler = pickle.load(open(min_max_scaler_path, 'rb'))\n",
    "\n",
    "    normalize_features = ['pagerank','retrieval_score','monge_elkan','des_cont_jaccard',\n",
    "                         'jaro_winkler','levenshtein','singleton','is_lof','num_char','num_tokens', 'lof_property_count_tf_idf_score',\n",
    "                         'lof-graph-embedding-score', 'lof-reciprocal-rank', 'context_score']\n",
    "    df[normalize_features] = df[normalize_features].astype('float64')\n",
    "    grouped_obj = df.groupby(['column', 'row'])\n",
    "    new_df_list = []\n",
    "    pred = []\n",
    "    for cell in grouped_obj:\n",
    "        cell[1][normalize_features] = scaler.transform(cell[1][normalize_features])\n",
    "        df_copy = cell[1].copy()\n",
    "        df_features = df_copy[normalize_features]\n",
    "        new_df_list.append(df_copy)\n",
    "        arr = df_features.to_numpy()\n",
    "        test_inp = []\n",
    "        for a in arr:\n",
    "            test_inp.append(a)\n",
    "        test_tensor = torch.tensor(test_inp).float()\n",
    "        scores = model.predict(test_tensor)\n",
    "        pred.extend(torch.squeeze(scores).tolist())\n",
    "    out_df = pd.concat(new_df_list)\n",
    "    out_df[output_column] = pred\n",
    "    \n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82c323a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For file:  28086084_0_3127660530989916727.csv\n",
      "Top_1 Accuracy:  0.7863636363636364\n",
      "For file:  84575189_0_6365692015941409487.csv\n",
      "Top_1 Accuracy:  0.9285714285714286\n",
      "For file:  29414811_2_4773219892816395776.csv\n",
      "Top_1 Accuracy:  0.7727272727272727\n",
      "For file:  14067031_0_559833072073397908.csv\n",
      "Top_1 Accuracy:  0.9433962264150944\n",
      "For file:  50270082_0_444360818941411589.csv\n",
      "Top_1 Accuracy:  0.9702380952380952\n",
      "For file:  52299421_0_4473286348258170200.csv\n",
      "Top_1 Accuracy:  0.8901098901098901\n",
      "For file:  14380604_4_3329235705746762392.csv\n",
      "Top_1 Accuracy:  0.95\n",
      "For file:  39759273_0_1427898308030295194.csv\n",
      "Top_1 Accuracy:  0.98\n",
      "For file:  45073662_0_3179937335063201739.csv\n",
      "Top_1 Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "#This code cell predicts for each test file and creates the top 5 candidates.\n",
    "for file in glob.glob(dev_path + '*.csv'):\n",
    "    filename = file.split(\"/\")[-1]\n",
    "    print(\"For file: \", filename)\n",
    "    #location where the output generated by the predictions wil be stored.\n",
    "    dev_output = os.path.join(dev_predictions, filename)\n",
    "    #Location where top 5 candidates will be stored for each cell in the file.\n",
    "    top_5_output_file = os.path.join(temp_predicted_top_5, filename)\n",
    "    df = pd.read_csv(file,dtype=object)\n",
    "    \n",
    "    predicted_df = predict(output_column=output_col, ranking_model= saved_model, min_max_scaler_path=normalization_file_path, df=df)\n",
    "    #Now, we add a column rank in this file which is sorted by the output_col.\n",
    "    predicted_df['rank'] = 0\n",
    "    predicted_df = predicted_df.sort_values([output_col], ascending = False)\n",
    "    grouped_obj = predicted_df.groupby(['row', 'column'])\n",
    "    for cell, group in grouped_obj:\n",
    "        m = len(group.index)\n",
    "        rank_list = list(range(1, m+1, 1))\n",
    "        group['rank'] = rank_list\n",
    "        for row, index in group.iterrows():\n",
    "            predicted_df.loc[row, 'rank'] = index['rank']\n",
    "            #print(predicted_df.loc[row, 'rank'])\n",
    "    predicted_df.to_csv(dev_output, index = False)\n",
    "    predicted_df['table_id'] ='0'\n",
    "    res, candidate_eval_data = parse_eval_files_stats(predicted_df, output_col)\n",
    "    top1_precision = res['num_tasks_with_model_score_top_one_accurate']/res['num_tasks_with_gt']\n",
    "    print(\"Top_1 Accuracy: \",top1_precision)\n",
    "    !tl get-kg-links -c $output_col -k 5 --k-rows {dev_output} > {top_5_output_file}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "222837e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following code block adds the correct column, adds the correct candidate in case it is not present in top 5. Also creates the correct_vs_incorrect.xlsx\n",
    "correct_df = pd.DataFrame()\n",
    "incorrect_df = pd.DataFrame()\n",
    "for file in glob.glob(temp_predicted_top_5 + '*.csv'):\n",
    "    #Create a correct column with a value either -1, 1, 0.\n",
    "    file_df = pd.read_csv(file)\n",
    "    file_df['correct'] = 0\n",
    "    filename = file.split(\"/\")[-1]\n",
    "    filename_colored = filename.replace('.csv', '.xlsx')\n",
    "    extra_df = pd.DataFrame()\n",
    "    output_file_path = os.path.join(temp, filename)\n",
    "    rank_file_path = os.path.join(dev_predictions, filename)\n",
    "    rank_file = pd.read_csv(rank_file_path)\n",
    "    grouped_obj = file_df.groupby(['row', 'column'])\n",
    "    for cell, group in grouped_obj:\n",
    "        m = len(group.index)\n",
    "        eval_pred_val = group['evaluation_label'].values.tolist()\n",
    "        group['rank'] = list(range(1, m+1, 1))\n",
    "        final_correct = []\n",
    "\n",
    "        if eval_pred_val[0] == 1:\n",
    "            final_correct =[1 for i in range(m)]   \n",
    "            group['correct'] = final_correct\n",
    "            \n",
    "        elif 1 in eval_pred_val:\n",
    "            final_correct = [0 for i in range(m)]  \n",
    "            group['correct'] = final_correct\n",
    "            incorrect_row = group.iloc[[0]]\n",
    "            incorrect_row = incorrect_row.copy()\n",
    "            incorrect_row['table_id'] = filename.split('.csv')[0]\n",
    "            incorrect_df = pd.concat([incorrect_df, incorrect_row])\n",
    "            cond = group.evaluation_label == 1\n",
    "            correct_row = group.loc[cond, :]\n",
    "            correct_row = correct_row.copy()\n",
    "            correct_row['table_id'] = filename.split('.csv')[0]\n",
    "            correct_df = correct_df.append(correct_row, ignore_index=True)\n",
    "            \n",
    "        else:\n",
    "            final_correct = [-1 for i in range(m)]    \n",
    "            group['correct'] = final_correct\n",
    "            group_2 = group.copy()\n",
    "            row = group_2['row'].values[0]\n",
    "            column = group_2['column'].values[0]\n",
    "            group2 = group_2.sort_index(inplace=True)\n",
    "            ind = rank_file[(rank_file['row']==row) & (rank_file['column']==column) & (rank_file['evaluation_label']==1)].index.values\n",
    "            if len(ind) > 1:\n",
    "                ind_true = ind[0]\n",
    "                corr = rank_file.iloc[[ind_true]]\n",
    "            elif len(ind) == 1:\n",
    "                corr = rank_file.iloc[ind]\n",
    "            else:\n",
    "                continue\n",
    "            corr_df = pd.DataFrame()\n",
    "            corr_df = corr.copy()\n",
    "            corr_df.loc[:,'correct'] = -1\n",
    "            extra_df = pd.concat([extra_df, corr_df])\n",
    "            corr_df['table_id'] = filename.split('.csv')[0]\n",
    "            correct_df = correct_df.append(corr_df, ignore_index=True)\n",
    "            incorrect_row = group.iloc[[0]]\n",
    "            incorrect_row = incorrect_row.copy()\n",
    "            incorrect_row['table_id'] = filename.split('.csv')[0]\n",
    "            incorrect_df = pd.concat([incorrect_df, incorrect_row])\n",
    "                \n",
    "        #Find the correct column from the rank file \n",
    "        for row, index in group.iterrows():\n",
    "            file_df.loc[row, 'correct'] = index['correct'] \n",
    "            file_df.loc[row, 'rank'] = index['rank']\n",
    "            \n",
    "    file_df = pd.concat([file_df, extra_df])\n",
    "    file_df = file_df.sort_values(['column', 'row', 'rank'], ascending = True)\n",
    "    file_df.to_csv(output_file_path, index=False)\n",
    "incorrect_df['row_type'] = \"Incorrect\"\n",
    "correct_df['row_type'] = \"Correct\"\n",
    "result_df = pd.concat([correct_df, incorrect_df])\n",
    "result_df = result_df.sort_values([\"table_id\",\"row\", \"column\", \"label\", \"rank\"], ascending = True)\n",
    "output_path = os.path.join(temp,\"correctandincorrect.csv\")\n",
    "result_df.to_csv(output_path, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "90b02e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>row</th>\n",
       "      <th>label</th>\n",
       "      <th>context</th>\n",
       "      <th>label_clean</th>\n",
       "      <th>kg_id</th>\n",
       "      <th>kg_labels</th>\n",
       "      <th>kg_aliases</th>\n",
       "      <th>method</th>\n",
       "      <th>kg_descriptions</th>\n",
       "      <th>...</th>\n",
       "      <th>levenshtein</th>\n",
       "      <th>class_tfidf_reciprocal_rank</th>\n",
       "      <th>property_tfidf_reciprocal_rank</th>\n",
       "      <th>context_properties</th>\n",
       "      <th>context_score</th>\n",
       "      <th>siamese_pred</th>\n",
       "      <th>rank</th>\n",
       "      <th>correct</th>\n",
       "      <th>table_id</th>\n",
       "      <th>row_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Abraham the Syrian</td>\n",
       "      <td>--|Yes|--|--|--</td>\n",
       "      <td>Abraham the Syrian</td>\n",
       "      <td>Q200608</td>\n",
       "      <td>Ephrem the Syrian</td>\n",
       "      <td>Ephraem Syrus</td>\n",
       "      <td>fuzzy-augmented</td>\n",
       "      <td>4th century Syriac deacon, hymnographer and th...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN|NaN|NaN|NaN|NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9.995826e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>28086084_0_3127660530989916727</td>\n",
       "      <td>Incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Abraham the Syrian</td>\n",
       "      <td>--|Yes|--|--|--</td>\n",
       "      <td>Abraham the Syrian</td>\n",
       "      <td>Q1292819</td>\n",
       "      <td>Pope Abraham of Alexandria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fuzzy-augmented</td>\n",
       "      <td>Coptic Orthodox Pope of Alexandria, Egypt</td>\n",
       "      <td>...</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>NaN|NaN|NaN|NaN|NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.628786e-11</td>\n",
       "      <td>41</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>28086084_0_3127660530989916727</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>Alban</td>\n",
       "      <td>Yes|--|Yes|Yes|--</td>\n",
       "      <td>Alban</td>\n",
       "      <td>Q56464777</td>\n",
       "      <td>Ashley Alban</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fuzzy-augmented</td>\n",
       "      <td>American pornographic actress</td>\n",
       "      <td>...</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.009434</td>\n",
       "      <td>P1340|NaN|P1340|P1340|NaN</td>\n",
       "      <td>0.7023</td>\n",
       "      <td>9.370953e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28086084_0_3127660530989916727</td>\n",
       "      <td>Incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>Alban</td>\n",
       "      <td>Yes|--|Yes|Yes|--</td>\n",
       "      <td>Alban</td>\n",
       "      <td>Q312982</td>\n",
       "      <td>Alban</td>\n",
       "      <td>St. Alban|Albanus|Saint Alban</td>\n",
       "      <td>exact-match</td>\n",
       "      <td>English protomartyr</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN|NaN|NaN|NaN|NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.818838e-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28086084_0_3127660530989916727</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>Alphege</td>\n",
       "      <td>--|--|--|Yes|--</td>\n",
       "      <td>Alphege</td>\n",
       "      <td>Q4735284</td>\n",
       "      <td>Alphege of Wells</td>\n",
       "      <td>Elfheah|Ælfheah</td>\n",
       "      <td>exact-match</td>\n",
       "      <td>Bishop of Wells</td>\n",
       "      <td>...</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>NaN|NaN|NaN|NaN|NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9.999716e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28086084_0_3127660530989916727</td>\n",
       "      <td>Incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>Angewandte Chemie International Edition</td>\n",
       "      <td>61|109</td>\n",
       "      <td>Angewandte Chemie International Edition</td>\n",
       "      <td>Q538683</td>\n",
       "      <td>Angewandte Chemie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fuzzy-augmented</td>\n",
       "      <td>journal</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435897</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN|NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9.998993e-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84575189_0_6365692015941409487</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>Journal of the American Veterinary Medical Ass...</td>\n",
       "      <td>93|78</td>\n",
       "      <td>Journal of the American Veterinary Medical Ass...</td>\n",
       "      <td>Q1470970</td>\n",
       "      <td>Journal of the American Medical Association</td>\n",
       "      <td>Jour. A.M.A.|JAMA|Journal of the American Medi...</td>\n",
       "      <td>fuzzy-augmented</td>\n",
       "      <td>peer-reviewed medical journal</td>\n",
       "      <td>...</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN|NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9.999889e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>84575189_0_6365692015941409487</td>\n",
       "      <td>Incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>Journal of the American Veterinary Medical Ass...</td>\n",
       "      <td>93|78</td>\n",
       "      <td>Journal of the American Veterinary Medical Ass...</td>\n",
       "      <td>Q2843064</td>\n",
       "      <td>American Veterinary Medical Association</td>\n",
       "      <td>AVMA</td>\n",
       "      <td>fuzzy-augmented</td>\n",
       "      <td>organization</td>\n",
       "      <td>...</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>NaN|NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.141063e-03</td>\n",
       "      <td>18</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>84575189_0_6365692015941409487</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>2</td>\n",
       "      <td>98</td>\n",
       "      <td>virology</td>\n",
       "      <td>99|75</td>\n",
       "      <td>virology</td>\n",
       "      <td>Q7215</td>\n",
       "      <td>virology</td>\n",
       "      <td>NaN</td>\n",
       "      <td>exact-match</td>\n",
       "      <td>study of viruses</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>NaN|NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9.999987e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84575189_0_6365692015941409487</td>\n",
       "      <td>Incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2</td>\n",
       "      <td>98</td>\n",
       "      <td>virology</td>\n",
       "      <td>99|75</td>\n",
       "      <td>virology</td>\n",
       "      <td>Q7934867</td>\n",
       "      <td>Virology</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fuzzy-augmented</td>\n",
       "      <td>scientific journal</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>NaN|NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9.921612e-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84575189_0_6365692015941409487</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     column  row                                              label  \\\n",
       "0         0    0                                 Abraham the Syrian   \n",
       "12        0    0                                 Abraham the Syrian   \n",
       "65        0   11                                              Alban   \n",
       "13        0   11                                              Alban   \n",
       "175       0   13                                            Alphege   \n",
       "..      ...  ...                                                ...   \n",
       "54        2   60            Angewandte Chemie International Edition   \n",
       "456       2   92  Journal of the American Veterinary Medical Ass...   \n",
       "55        2   92  Journal of the American Veterinary Medical Ass...   \n",
       "486       2   98                                           virology   \n",
       "56        2   98                                           virology   \n",
       "\n",
       "               context                                        label_clean  \\\n",
       "0      --|Yes|--|--|--                                 Abraham the Syrian   \n",
       "12     --|Yes|--|--|--                                 Abraham the Syrian   \n",
       "65   Yes|--|Yes|Yes|--                                              Alban   \n",
       "13   Yes|--|Yes|Yes|--                                              Alban   \n",
       "175    --|--|--|Yes|--                                            Alphege   \n",
       "..                 ...                                                ...   \n",
       "54              61|109            Angewandte Chemie International Edition   \n",
       "456              93|78  Journal of the American Veterinary Medical Ass...   \n",
       "55               93|78  Journal of the American Veterinary Medical Ass...   \n",
       "486              99|75                                           virology   \n",
       "56               99|75                                           virology   \n",
       "\n",
       "         kg_id                                    kg_labels  \\\n",
       "0      Q200608                            Ephrem the Syrian   \n",
       "12    Q1292819                   Pope Abraham of Alexandria   \n",
       "65   Q56464777                                 Ashley Alban   \n",
       "13     Q312982                                        Alban   \n",
       "175   Q4735284                             Alphege of Wells   \n",
       "..         ...                                          ...   \n",
       "54     Q538683                            Angewandte Chemie   \n",
       "456   Q1470970  Journal of the American Medical Association   \n",
       "55    Q2843064      American Veterinary Medical Association   \n",
       "486      Q7215                                     virology   \n",
       "56    Q7934867                                     Virology   \n",
       "\n",
       "                                            kg_aliases           method  \\\n",
       "0                                        Ephraem Syrus  fuzzy-augmented   \n",
       "12                                                 NaN  fuzzy-augmented   \n",
       "65                                                 NaN  fuzzy-augmented   \n",
       "13                       St. Alban|Albanus|Saint Alban      exact-match   \n",
       "175                                    Elfheah|Ælfheah      exact-match   \n",
       "..                                                 ...              ...   \n",
       "54                                                 NaN  fuzzy-augmented   \n",
       "456  Jour. A.M.A.|JAMA|Journal of the American Medi...  fuzzy-augmented   \n",
       "55                                                AVMA  fuzzy-augmented   \n",
       "486                                                NaN      exact-match   \n",
       "56                                                 NaN  fuzzy-augmented   \n",
       "\n",
       "                                       kg_descriptions  ...  levenshtein  \\\n",
       "0    4th century Syriac deacon, hymnographer and th...  ...     0.666667   \n",
       "12           Coptic Orthodox Pope of Alexandria, Egypt  ...     0.423077   \n",
       "65                       American pornographic actress  ...     0.416667   \n",
       "13                                 English protomartyr  ...     1.000000   \n",
       "175                                    Bishop of Wells  ...     0.437500   \n",
       "..                                                 ...  ...          ...   \n",
       "54                                             journal  ...     0.435897   \n",
       "456                      peer-reviewed medical journal  ...     0.796296   \n",
       "55                                        organization  ...     0.722222   \n",
       "486                                   study of viruses  ...     1.000000   \n",
       "56                                  scientific journal  ...     1.000000   \n",
       "\n",
       "     class_tfidf_reciprocal_rank property_tfidf_reciprocal_rank  \\\n",
       "0                       0.142857                       1.000000   \n",
       "12                      1.000000                       0.047619   \n",
       "65                      0.019231                       0.009434   \n",
       "13                      0.014085                       0.166667   \n",
       "175                     0.333333                       0.062500   \n",
       "..                           ...                            ...   \n",
       "54                      0.250000                       1.000000   \n",
       "456                     0.062500                       1.000000   \n",
       "55                      0.013514                       0.014286   \n",
       "486                     0.015385                       0.014493   \n",
       "56                      1.000000                       0.200000   \n",
       "\n",
       "            context_properties  context_score  siamese_pred  rank  correct  \\\n",
       "0          NaN|NaN|NaN|NaN|NaN         0.0000  9.995826e-01     1     -1.0   \n",
       "12         NaN|NaN|NaN|NaN|NaN         0.0000  2.628786e-11    41     -1.0   \n",
       "65   P1340|NaN|P1340|P1340|NaN         0.7023  9.370953e-01     1      0.0   \n",
       "13         NaN|NaN|NaN|NaN|NaN         0.0000  4.818838e-01     2      0.0   \n",
       "175        NaN|NaN|NaN|NaN|NaN         0.0000  9.999716e-01     1      0.0   \n",
       "..                         ...            ...           ...   ...      ...   \n",
       "54                     NaN|NaN         0.0000  9.998993e-01     2      0.0   \n",
       "456                    NaN|NaN         0.0000  9.999889e-01     1     -1.0   \n",
       "55                     NaN|NaN         0.0000  1.141063e-03    18     -1.0   \n",
       "486                    NaN|NaN         0.0000  9.999987e-01     1      0.0   \n",
       "56                     NaN|NaN         0.0000  9.921612e-01     2      0.0   \n",
       "\n",
       "                           table_id   row_type  \n",
       "0    28086084_0_3127660530989916727  Incorrect  \n",
       "12   28086084_0_3127660530989916727    Correct  \n",
       "65   28086084_0_3127660530989916727  Incorrect  \n",
       "13   28086084_0_3127660530989916727    Correct  \n",
       "175  28086084_0_3127660530989916727  Incorrect  \n",
       "..                              ...        ...  \n",
       "54   84575189_0_6365692015941409487    Correct  \n",
       "456  84575189_0_6365692015941409487  Incorrect  \n",
       "55   84575189_0_6365692015941409487    Correct  \n",
       "486  84575189_0_6365692015941409487  Incorrect  \n",
       "56   84575189_0_6365692015941409487    Correct  \n",
       "\n",
       "[114 rows x 40 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bdd9a075",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding color to the final file\n",
    "!tl add-color -c $output_col -k 2 $output_path --output $correct_vs_incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083111bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
